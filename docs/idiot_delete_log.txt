 1 -"""
       2 -Pier + Bridge Playlist Builder
       3 -==============================
       4 -
       5 -A new playlist ordering strategy where:
       6 -- Each seed track is a fixed "pier"
       7 -- Bridge segments connect consecutive piers
       8 -- No repair pass after ordering
       9 -
      10 -Key features:
      11 -- Candidate pool deduped BEFORE ordering (no duplicate songs by normalized artist+title)
      12 -- Genre gating stays enabled with hard floors (no relaxation)
      13 -- Global used_track_ids prevents duplicates across segments
      14 -- One track per artist per segment enforced during beam search
      15 -- Cross-segment min_gap enforced during generation via boundary-aware constraints
      16 -- No post-order filtering or dropping (guarantees exact length)
      17 -- Single seed mode: seed acts as both start AND end pier, creating an arc structure
      18 -- Seed artist is allowed in bridges with same constraints as other artists
      19 -"""
      20 -
      21 -from __future__ import annotations
      22 -
      23 -import heapq
      24 -import itertools
      25 -import logging
      26 -import math
      27 -from pathlib import Path
      28 -from dataclasses import dataclass, field, replace
      29 -from typing import Any, Dict, List, Optional, Set, Tuple
      30 -
      31 -import numpy as np
      32 -import yaml
      33 -
      34 -from src.features.artifacts import ArtifactBundle, get_sonic_matrix
      35 -from src.title_dedupe import normalize_title_for_dedupe, normalize_artist_key
      36 -from src.string_utils import sanitize_for_logging
      37 -from src.playlist.identity_keys import identity_keys_for_index
      38 -from src.playlist.artist_identity_resolver import (
      39 -    ArtistIdentityConfig,
      40 -    resolve_artist_identity_keys,
      41 -    format_identity_keys_for_logging,
      42 -)
      43 -from src.playlist.config import resolve_pier_bridge_tuning as _resolve_pier_bridge_tuning_cfg
      44 -from src.playlist.run_audit import InfeasibleHandlingConfig, RunAuditConfig, RunAuditEvent, now_utc_iso
      45 -
      46 -# Phase 3 extracted modules
      47 -from src.playlist.scoring import (
      48 -    compute_transition_score as _compute_transition_score_extracted,
      49 -    compute_bridgeability_score as _compute_bridgeability_score_extracted,
      50 -)
      51 -from src.playlist.segment_pool_builder import (
      52 -    SegmentCandidatePoolBuilder,
      53 -    SegmentPoolConfig,
      54 -)
      55 -from src.playlist.pier_bridge_diagnostics import (
      56 -    SegmentDiagnostics as _SegmentDiagnosticsExtracted,
      57 -    PierBridgeDiagnosticsCollector,
      58 -)
      59 -
      60 -logger = logging.getLogger(__name__)
      61 -
      62 -
      63 -@dataclass
      64 -class PierBridgeConfig:
      65 -    """Configuration for pier + bridge playlist builder."""
      66 -    # NOTE: Defaults represent the recommended "dynamic" mode behavior. Narrow
      67 -    # mode defaults are resolved by the DS pipeline config layer.
      68 -    transition_floor: float = 0.35
      69 -    bridge_floor: float = 0.03  # min(simA, simB) for bridge candidates
      70 -    center_transitions: bool = False  # if True, mean-center transition mats and rescale sims to [0,1]
      71 -    transition_weights: Optional[tuple[float, float, float]] = None  # (rhythm, timbre, harmony)
      72 -    sonic_variant: Optional[str] = None  # sonic sim space for bridge gating/endpoint sims
      73 -    initial_neighbors_m: int = 100
      74 -    initial_bridge_helpers: int = 50
      75 -    max_neighbors_m: int = 400
      76 -    max_bridge_helpers: int = 200
      77 -    initial_beam_width: int = 20
      78 -    max_beam_width: int = 100
      79 -    max_expansion_attempts: int = 4
      80 -    eta_destination_pull: float = 0.10
      81 -    # Transition scoring weights
      82 -    weight_end_start: float = 0.70
      83 -    weight_mid_mid: float = 0.15
      84 -    weight_full_full: float = 0.15
      85 -    # Bridge scoring weights
      86 -    weight_bridge: float = 0.6
      87 -    weight_transition: float = 0.4
      88 -    genre_tiebreak_weight: float = 0.05
      89 -    # Soft genre penalty (does not gate candidates): if edge_genre < threshold,
      90 -    # multiply the edge score by (1 - strength).
      91 -    genre_penalty_threshold: float = 0.20
      92 -    genre_penalty_strength: float = 0.10
      93 -    # Medium-firm duration penalty: asymmetric penalty for candidates longer than pier reference
      94 -    # (does not gate candidates, but significantly reduces score for long tracks)
      95 -    duration_penalty_enabled: bool = True
      96 -    duration_penalty_weight: float = 0.30
      97 -    # Segment candidate pool strategy:
      98 -    # - "segment_scored": score candidates jointly vs (pierA,pierB) and take top-K
      99 -    # - "legacy": neighbors(A) ∪ neighbors(B) ∪ helpers (debug/compat only)
     100 -    segment_pool_strategy: str = "segment_scored"
     101 -    segment_pool_max: int = 400
     102 -    max_segment_pool_max: int = 1200
     103 -    # Progress model (A→B) to avoid "teleporting" / bouncing.
     104 -    progress_enabled: bool = True
     105 -    progress_monotonic_epsilon: float = 0.05
     106 -    progress_penalty_weight: float = 0.15
     107 -    # Interior artist policies (configured/wired by pipeline for legacy --artist runs).
     108 -    disallow_pier_artists_in_interiors: bool = False
     109 -    disallow_seed_artist_in_interiors: bool = False
     110 -    # Experiment-only bridge scoring (dry-run/audit only; production disabled).
     111 -    experiment_bridge_scoring_enabled: bool = False
     112 -    experiment_bridge_min_weight: float = 0.25
     113 -    experiment_bridge_balance_weight: float = 0.15
     114 -    # Progress arc scoring (feature-flagged; default disabled).
     115 -    progress_arc_enabled: bool = False
     116 -    progress_arc_weight: float = 0.25
     117 -    progress_arc_shape: str = "linear"
     118 -    progress_arc_tolerance: float = 0.0
     119 -    progress_arc_loss: str = "abs"
     120 -    progress_arc_huber_delta: float = 0.10
     121 -    progress_arc_max_step: Optional[float] = None
     122 -    progress_arc_max_step_mode: str = "penalty"
     123 -    progress_arc_max_step_penalty: float = 0.25
     124 -    progress_arc_autoscale_enabled: bool = False
     125 -    progress_arc_autoscale_min_distance: float = 0.05
     126 -    progress_arc_autoscale_distance_scale: float = 0.50
     127 -    progress_arc_autoscale_per_step_scale: bool = False
     128 -    # Optional genre tie-break band for penalty application (default off).
     129 -    genre_tie_break_band: Optional[float] = None
     130 -    # DJ-style genre bridging (opt-in; default disabled).
     131 -    dj_bridging_enabled: bool = False
     132 -    dj_seed_ordering: str = "auto"  # auto | fixed
     133 -    dj_anchors_must_include_all: bool = True
     134 -    dj_route_shape: str = "linear"  # linear | arc | ladder (MVP uses linear)
     135 -    dj_waypoint_weight: float = 0.15
     136 -    dj_waypoint_floor: float = 0.20
     137 -    dj_waypoint_penalty: float = 0.10
     138 -    dj_waypoint_tie_break_band: Optional[float] = None
     139 -    dj_waypoint_cap: float = 0.05
     140 -    dj_seed_ordering_weight_sonic: float = 0.60
     141 -    dj_seed_ordering_weight_genre: float = 0.20
     142 -    dj_seed_ordering_weight_bridge: float = 0.20
     143 -    dj_pooling_strategy: str = "baseline"  # baseline | dj_union
     144 -    dj_pooling_k_local: int = 200
     145 -    dj_pooling_k_toward: int = 80
     146 -    dj_pooling_k_genre: int = 80
     147 -    dj_pooling_k_union_max: int = 900
     148 -    dj_pooling_step_stride: int = 1
     149 -    dj_pooling_cache_enabled: bool = True
     150 -    dj_allow_detours_when_far: bool = True
     151 -    dj_far_threshold_sonic: float = 0.45
     152 -    dj_far_threshold_genre: float = 0.60
     153 -    dj_far_threshold_connector_scarcity: float = 0.10
     154 -    dj_connector_bias_enabled: bool = True
     155 -    dj_connector_max_per_segment_linear: int = 1
     156 -    dj_connector_max_per_segment_adventurous: int = 3
     157 -    dj_ladder_top_labels: int = 5
     158 -    dj_ladder_min_label_weight: float = 0.05
     159 -    dj_ladder_min_similarity: float = 0.20
     160 -    dj_ladder_max_steps: int = 6
     161 -    dj_waypoint_fallback_k: int = 25
     162 -    dj_micro_piers_enabled: bool = False
     163 -    dj_micro_piers_max: int = 1
     164 -    dj_micro_piers_topk: int = 5
     165 -
     166 -
     167 -# Backward compatibility: SegmentDiagnostics now imported from extracted module
     168 -# Kept here as alias for existing code
     169 -SegmentDiagnostics = _SegmentDiagnosticsExtracted
     170 -
     171 -
     172 -@dataclass
     173 -class PierBridgeResult:
     174 -    """Result of pier + bridge playlist construction."""
     175 -    track_ids: List[str]
     176 -    track_indices: List[int]
     177 -    seed_positions: List[int]  # positions of seeds in final playlist
     178 -    segment_diagnostics: List[SegmentDiagnostics]
     179 -    stats: Dict[str, Any]
     180 -    success: bool = True
     181 -    failure_reason: Optional[str] = None
     182 -    bridge_debug: list = field(default_factory=list)
     183 -
     184 -
     185 -def resolve_pier_bridge_tuning(
     186 -    overrides: Optional[dict],
     187 -    mode: str,
     188 -) -> dict:
     189 -    """Backward-compatible wrapper around the canonical resolver in `src.playlist.config`."""
     190 -    similarity_floor = 0.0
     191 -    if isinstance(overrides, dict):
     192 -        cand = overrides.get("candidate_pool", {}) or {}
     193 -        if isinstance(cand, dict) and isinstance(cand.get("similarity_floor"), (int, float)):
     194 -            similarity_floor = float(cand.get("similarity_floor"))
     195 -
     196 -    tuning, _ = _resolve_pier_bridge_tuning_cfg(
     197 -        mode=str(mode).strip().lower(),  # type: ignore[arg-type]
     198 -        similarity_floor=float(similarity_floor),
     199 -        overrides=overrides if isinstance(overrides, dict) else None,
     200 -    )
     201 -    return {
     202 -        "transition_floor": float(tuning.transition_floor),
     203 -        "bridge_floor": float(tuning.bridge_floor),
     204 -        "weight_bridge": float(tuning.weight_bridge),
     205 -        "weight_transition": float(tuning.weight_transition),
     206 -        "genre_tiebreak_weight": float(tuning.genre_tiebreak_weight),
     207 -        "genre_penalty_threshold": float(tuning.genre_penalty_threshold),
     208 -        "genre_penalty_strength": float(tuning.genre_penalty_strength),
     209 -    }
     210 -
     211 -
     212 -def _l2_normalize_rows(X: np.ndarray) -> np.ndarray:
     213 -    """L2 normalize each row of a matrix."""
     214 -    norms = np.linalg.norm(X, axis=1, keepdims=True)
     215 -    norms = np.where(norms < 1e-12, 1.0, norms)
     216 -    return X / norms
     217 -
     218 -
     219 -def _cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
     220 -    """Cosine similarity between two vectors."""
     221 -    norm_a = np.linalg.norm(a)
     222 -    norm_b = np.linalg.norm(b)
     223 -    if norm_a < 1e-12 or norm_b < 1e-12:
     224 -        return 0.0
     225 -    return float(np.dot(a, b) / (norm_a * norm_b))
     226 -
     227 -
     228 -def _compute_transition_score(
     229 -    idx_a: int,
     230 -    idx_b: int,
     231 -    X_full: np.ndarray,
     232 -    X_start: Optional[np.ndarray],
     233 -    X_mid: Optional[np.ndarray],
     234 -    X_end: Optional[np.ndarray],
     235 -    cfg: PierBridgeConfig,
     236 -) -> float:
     237 -    """
     238 -    Compute multi-segment transition score from track A to track B.
     239 -
     240 -    score = w_end_start * cos(end(A), start(B))
     241 -          + w_mid_mid * cos(mid(A), mid(B))
     242 -          + w_full_full * cos(full(A), full(B))
     243 -    """
     244 -    # NOTE: X_* matrices are expected to be row L2-normalized so dot() == cosine.
     245 -    sim_full = float(np.dot(X_full[idx_a], X_full[idx_b]))
     246 -
     247 -    # End-start similarity (use full as fallback)
     248 -    if X_end is not None and X_start is not None:
     249 -        sim_end_start = float(np.dot(X_end[idx_a], X_start[idx_b]))
     250 -    else:
     251 -        sim_end_start = sim_full
     252 -
     253 -    # Mid-mid similarity (use full as fallback)
     254 -    if X_mid is not None:
     255 -        sim_mid = float(np.dot(X_mid[idx_a], X_mid[idx_b]))
     256 -    else:
     257 -        sim_mid = sim_full
     258 -
     259 -    if cfg.center_transitions:
     260 -        # When centering is enabled, rescale cosine sims from [-1,1] to [0,1]
     261 -        sim_full = (sim_full + 1.0) / 2.0
     262 -        sim_end_start = (sim_end_start + 1.0) / 2.0
     263 -        sim_mid = (sim_mid + 1.0) / 2.0
     264 -
     265 -    return (
     266 -        cfg.weight_end_start * sim_end_start
     267 -        + cfg.weight_mid_mid * sim_mid
     268 -        + cfg.weight_full_full * sim_full
     269 -    )
     270 -
     271 -
     272 -def _compute_transition_score_raw_and_transformed(
     273 -    idx_a: int,
     274 -    idx_b: int,
     275 -    X_full: np.ndarray,
     276 -    X_start: Optional[np.ndarray],
     277 -    X_mid: Optional[np.ndarray],
     278 -    X_end: Optional[np.ndarray],
     279 -    cfg: PierBridgeConfig,
     280 -) -> tuple[float, float]:
     281 -    """
     282 -    Return (raw, transformed) transition scores where "transformed" matches
     283 -    `_compute_transition_score()`, and "raw" is before optional centering/rescale.
     284 -    """
     285 -    sim_full_raw = float(np.dot(X_full[idx_a], X_full[idx_b]))
     286 -    if X_end is not None and X_start is not None:
     287 -        sim_end_start_raw = float(np.dot(X_end[idx_a], X_start[idx_b]))
     288 -    else:
     289 -        sim_end_start_raw = sim_full_raw
     290 -    if X_mid is not None:
     291 -        sim_mid_raw = float(np.dot(X_mid[idx_a], X_mid[idx_b]))
     292 -    else:
     293 -        sim_mid_raw = sim_full_raw
     294 -
     295 -    raw = (
     296 -        cfg.weight_end_start * sim_end_start_raw
     297 -        + cfg.weight_mid_mid * sim_mid_raw
     298 -        + cfg.weight_full_full * sim_full_raw
     299 -    )
     300 -
     301 -    if not cfg.center_transitions:
     302 -        return raw, raw
     303 -
     304 -    sim_full = (sim_full_raw + 1.0) / 2.0
     305 -    sim_end_start = (sim_end_start_raw + 1.0) / 2.0
     306 -    sim_mid = (sim_mid_raw + 1.0) / 2.0
     307 -    transformed = (
     308 -        cfg.weight_end_start * sim_end_start
     309 -        + cfg.weight_mid_mid * sim_mid
     310 -        + cfg.weight_full_full * sim_full
     311 -    )
     312 -    return raw, transformed
     313 -
     314 -
     315 -def _dist(values: list[float]) -> dict[str, Optional[float]]:
     316 -    if not values:
     317 -        return {"min": None, "p05": None, "p50": None, "p95": None, "max": None}
     318 -    arr = np.array([v for v in values if math.isfinite(v)], dtype=float)
     319 -    if arr.size == 0:
     320 -        return {"min": None, "p05": None, "p50": None, "p95": None, "max": None}
     321 -    return {
     322 -        "min": float(np.min(arr)),
     323 -        "p05": float(np.percentile(arr, 5)),
     324 -        "p50": float(np.percentile(arr, 50)),
     325 -        "p95": float(np.percentile(arr, 95)),
     326 -        "max": float(np.max(arr)),
     327 -    }
     328 -
     329 -
     330 -def _step_fraction(step_idx: int, steps: int) -> float:
     331 -    """Shared step fraction convention for progress + waypoint targets."""
     332 -    if steps <= 0:
     333 -        return 0.0
     334 -    return float(step_idx + 1) / float(steps + 1)
     335 -
     336 -
     337 -def _progress_target_curve(step_idx: int, steps: int, shape: str) -> float:
     338 -    if steps <= 0:
     339 -        return 0.0
     340 -    shape = str(shape or "linear").strip().lower()
     341 -    if shape not in {"linear", "arc"}:
     342 -        shape = "linear"
     343 -    base = _step_fraction(step_idx, steps)
     344 -    if shape == "arc":
     345 -        return 0.5 - 0.5 * math.cos(math.pi * base)
     346 -    return base
     347 -
     348 -
     349 -def _progress_arc_loss_value(err: float, loss: str, huber_delta: float) -> float:
     350 -    err = float(max(0.0, err))
     351 -    loss = str(loss or "abs").strip().lower()
     352 -    if loss == "squared":
     353 -        return float(err * err)
     354 -    if loss == "huber":
     355 -        delta = float(huber_delta) if math.isfinite(float(huber_delta)) else 0.1
     356 -        if delta <= 0:
     357 -            delta = 0.1
     358 -        if err <= delta:
     359 -            return float(0.5 * err * err)
     360 -        return float(delta * (err - 0.5 * delta))
     361 -    return float(err)
     362 -
     363 -
     364 -def _compute_progress_tracking_metrics(
     365 -    *,
     366 -    path: list[int],
     367 -    pier_a: int,
     368 -    pier_b: int,
     369 -    X_full_norm: np.ndarray,
     370 -    shape: str,
     371 -) -> dict[str, Optional[float]]:
     372 -    if not path:
     373 -        return {
     374 -            "mean_abs_dev": None,
     375 -            "p50_abs_dev": None,
     376 -            "p90_abs_dev": None,
     377 -            "max_progress_jump": None,
     378 -        }
     379 -
     380 -    vec_a_full = X_full_norm[pier_a]
     381 -    vec_b_full = X_full_norm[pier_b]
     382 -    d = vec_b_full - vec_a_full
     383 -    denom = float(np.dot(d, d))
     384 -    if (not math.isfinite(denom)) or denom <= 1e-12:
     385 -        return {
     386 -            "mean_abs_dev": None,
     387 -            "p50_abs_dev": None,
     388 -            "p90_abs_dev": None,
     389 -            "max_progress_jump": None,
     390 -        }
     391 -
     392 -    steps = len(path)
     393 -    devs: list[float] = []
     394 -    max_jump = None
     395 -    last_t = None
     396 -    for idx, track_idx in enumerate(path):
     397 -        t_raw = float(np.dot((X_full_norm[int(track_idx)] - vec_a_full), d) / denom)
     398 -        if not math.isfinite(t_raw):
     399 -            continue
     400 -        t = float(max(0.0, min(1.0, t_raw)))
     401 -        target_t = _progress_target_curve(idx, steps, shape)
     402 -        devs.append(abs(t - target_t))
     403 -        if last_t is not None:
     404 -            jump = t - last_t
     405 -            if max_jump is None or jump > max_jump:
     406 -                max_jump = jump
     407 -        last_t = t
     408 -
     409 -    if not devs:
     410 -        return {
     411 -            "mean_abs_dev": None,
     412 -            "p50_abs_dev": None,
     413 -            "p90_abs_dev": None,
     414 -            "max_progress_jump": None,
     415 -        }
     416 -
     417 -    dev_arr = np.array(devs, dtype=float)
     418 -    return {
     419 -        "mean_abs_dev": float(np.mean(dev_arr)),
     420 -        "p50_abs_dev": float(np.percentile(dev_arr, 50)),
     421 -        "p90_abs_dev": float(np.percentile(dev_arr, 90)),
     422 -        "max_progress_jump": (float(max_jump) if max_jump is not None else None),
     423 -    }
     424 -
     425 -
     426 -def _summarize_candidates_for_audit(
     427 -    *,
     428 -    candidates: list[int],
     429 -    pier_a: int,
     430 -    pier_b: int,
     431 -    X_full_norm: np.ndarray,
     432 -    X_full_tr_norm: np.ndarray,
     433 -    X_start_tr_norm: Optional[np.ndarray],
     434 -    X_mid_tr_norm: Optional[np.ndarray],
     435 -    X_end_tr_norm: Optional[np.ndarray],
     436 -    X_genre_norm: Optional[np.ndarray],
     437 -    cfg: PierBridgeConfig,
     438 -    bundle: ArtifactBundle,
     439 -    internal_connector_indices: Optional[Set[int]],
     440 -    top_k: int,
     441 -) -> tuple[list[dict[str, Any]], dict[str, dict[str, Optional[float]]]]:
     442 -    if not candidates:
     443 -        return [], {}
     444 -
     445 -    cand_sorted = sorted(set(int(i) for i in candidates))
     446 -    sim_to_a = np.dot(X_full_norm, X_full_norm[pier_a])
     447 -    sim_to_b = np.dot(X_full_norm, X_full_norm[pier_b])
     448 -
     449 -    # Progress diagnostics: projection onto the AB direction in the same sonic
     450 -    # similarity space used for endpoint sims.
     451 -    vec_a_full = X_full_norm[pier_a]
     452 -    vec_b_full = X_full_norm[pier_b]
     453 -    d = vec_b_full - vec_a_full
     454 -    denom_progress = float(np.dot(d, d))
     455 -    progress_active = bool(math.isfinite(denom_progress) and denom_progress > 1e-12)
     456 -
     457 -    sim_a_vals: list[float] = []
     458 -    sim_b_vals: list[float] = []
     459 -    hmean_vals: list[float] = []
     460 -    progress_vals: list[float] = []
     461 -    tmin_vals: list[float] = []
     462 -    t_a_raw_vals: list[float] = []
     463 -    t_b_raw_vals: list[float] = []
     464 -    t_a_vals: list[float] = []
     465 -    t_b_vals: list[float] = []
     466 -    gmin_vals: list[float] = []
     467 -    g_a_vals: list[float] = []
     468 -    g_b_vals: list[float] = []
     469 -
     470 -    genre_vec_a = X_genre_norm[pier_a] if X_genre_norm is not None else None
     471 -    genre_vec_b = X_genre_norm[pier_b] if X_genre_norm is not None else None
     472 -
     473 -    rows: list[dict[str, Any]] = []
     474 -    for cand in cand_sorted:
     475 -        keys = identity_keys_for_index(bundle, int(cand))
     476 -        sim_a = float(sim_to_a[cand])
     477 -        sim_b = float(sim_to_b[cand])
     478 -        denom = sim_a + sim_b
     479 -        hmean = 0.0 if denom <= 1e-9 else (2.0 * sim_a * sim_b) / denom
     480 -
     481 -        progress_t = None
     482 -        if progress_active:
     483 -            t_raw = float(np.dot((X_full_norm[cand] - vec_a_full), d) / denom_progress)
     484 -            if math.isfinite(t_raw):
     485 -                progress_t = float(max(0.0, min(1.0, t_raw)))
     486 -                progress_vals.append(float(progress_t))
     487 -
     488 -        t_a_raw, t_a = _compute_transition_score_raw_and_transformed(
     489 -            pier_a, cand, X_full_tr_norm, X_start_tr_norm, X_mid_tr_norm, X_end_tr_norm, cfg
     490 -        )
     491 -        t_b_raw, t_b = _compute_transition_score_raw_and_transformed(
     492 -            cand, pier_b, X_full_tr_norm, X_start_tr_norm, X_mid_tr_norm, X_end_tr_norm, cfg
     493 -        )
     494 -        t_min = min(t_a, t_b)
     495 -
     496 -        g_a = float("nan")
     497 -        g_b = float("nan")
     498 -        g_min = float("nan")
     499 -        if genre_vec_a is not None and genre_vec_b is not None:
     500 -            g_a = float(np.dot(genre_vec_a, X_genre_norm[cand]))  # type: ignore[index]
     501 -            g_b = float(np.dot(X_genre_norm[cand], genre_vec_b))  # type: ignore[index]
     502 -            g_min = min(g_a, g_b) if math.isfinite(g_a) and math.isfinite(g_b) else float("nan")
     503 -
     504 -        final = cfg.weight_bridge * hmean + cfg.weight_transition * t_min
     505 -        if math.isfinite(g_min) and cfg.genre_tiebreak_weight:
     506 -            final += float(cfg.genre_tiebreak_weight) * float(g_min)
     507 -        if (
     508 -            cfg.genre_penalty_strength > 0
     509 -            and math.isfinite(g_min)
     510 -            and float(g_min) < float(cfg.genre_penalty_threshold)
     511 -        ):
     512 -            final *= (1.0 - float(cfg.genre_penalty_strength))
     513 -
     514 -        artist = (
     515 -            str(bundle.track_artists[cand])
     516 -            if bundle.track_artists is not None
     517 -            else (str(bundle.artist_keys[cand]) if bundle.artist_keys is not None else "")
     518 -        )
     519 -        title = str(bundle.track_titles[cand]) if bundle.track_titles is not None else ""
     520 -        rows.append(
     521 -            {
     522 -                "track_id": str(bundle.track_ids[cand]),
     523 -                "artist": sanitize_for_logging(artist),
     524 -                "title": sanitize_for_logging(title),
     525 -                "artist_key": keys.artist_key,
     526 -                "title_key": keys.title_key,
     527 -                "progress_t": (round(float(progress_t), 3) if progress_t is not None else None),
     528 -                "simA": round(sim_a, 3),
     529 -                "simB": round(sim_b, 3),
     530 -                "hmean": round(hmean, 3),
     531 -                "bridge_sim": round(hmean, 3),
     532 -                "T_min": round(float(t_min), 3),
     533 -                "G_min": (round(float(g_min), 3) if math.isfinite(g_min) else None),
     534 -                "final": round(float(final), 3),
     535 -                "internal": bool(internal_connector_indices and cand in internal_connector_indices),
     536 -            }
     537 -        )
     538 -
     539 -        sim_a_vals.append(sim_a)
     540 -        sim_b_vals.append(sim_b)
     541 -        hmean_vals.append(hmean)
     542 -        tmin_vals.append(float(t_min))
     543 -        t_a_raw_vals.append(float(t_a_raw))
     544 -        t_b_raw_vals.append(float(t_b_raw))
     545 -        t_a_vals.append(float(t_a))
     546 -        t_b_vals.append(float(t_b))
     547 -        if math.isfinite(g_min):
     548 -            gmin_vals.append(float(g_min))
     549 -        if math.isfinite(g_a):
     550 -            g_a_vals.append(float(g_a))
     551 -        if math.isfinite(g_b):
     552 -            g_b_vals.append(float(g_b))
     553 -
     554 -    rows = sorted(rows, key=lambda r: (-float(r.get("final") or 0.0), str(r.get("track_id", ""))))[: max(0, int(top_k))]
     555 -
     556 -    dists: dict[str, dict[str, Optional[float]]] = {
     557 -        "simA": _dist(sim_a_vals),
     558 -        "simB": _dist(sim_b_vals),
     559 -        "hmean": _dist(hmean_vals),
     560 -        "progress_t": _dist(progress_vals),
     561 -        "T_min": _dist(tmin_vals),
     562 -        "T_raw_pierA_to_cand": _dist(t_a_raw_vals),
     563 -        "T_raw_cand_to_pierB": _dist(t_b_raw_vals),
     564 -        "T_pierA_to_cand": _dist(t_a_vals),
     565 -        "T_cand_to_pierB": _dist(t_b_vals),
     566 -    }
     567 -    if X_genre_norm is not None:
     568 -        dists["G_min"] = _dist(gmin_vals)
     569 -        dists["G_pierA_to_cand"] = _dist(g_a_vals)
     570 -        dists["G_cand_to_pierB"] = _dist(g_b_vals)
     571 -    return rows, dists
     572 -
     573 -
     574 -def _compute_bridgeability_score(
     575 -    idx_a: int,
     576 -    idx_b: int,
     577 -    X_full_norm: np.ndarray,
     578 -    X_start_norm: Optional[np.ndarray],
     579 -    X_end_norm: Optional[np.ndarray],
     580 -) -> float:
     581 -    """
     582 -    Cheap heuristic for how well two seeds can be bridged.
     583 -    Uses direct transition similarity plus a term for the distance between them.
     584 -    """
     585 -    # Direct transition similarity
     586 -    if X_end_norm is not None and X_start_norm is not None:
     587 -        direct_sim = float(np.dot(X_end_norm[idx_a], X_start_norm[idx_b]))
     588 -    else:
     589 -        direct_sim = float(np.dot(X_full_norm[idx_a], X_full_norm[idx_b]))
     590 -
     591 -    # Full similarity (for overall coherence)
     592 -    full_sim = float(np.dot(X_full_norm[idx_a], X_full_norm[idx_b]))
     593 -
     594 -    # Combine: favor pairs with good direct transitions
     595 -    return 0.6 * direct_sim + 0.4 * full_sim
     596 -
     597 -
     598 -def _normalize_vec(vec: np.ndarray) -> np.ndarray:
     599 -    norm = float(np.linalg.norm(vec))
     600 -    if not math.isfinite(norm) or norm <= 1e-12:
     601 -        return vec
     602 -    return vec / norm
     603 -
     604 -
     605 -def _genre_vocab_map(genre_vocab: np.ndarray) -> dict[str, int]:
     606 -    return {str(g).strip().lower(): int(i) for i, g in enumerate(genre_vocab)}
     607 -
     608 -
     609 -def _select_top_genre_labels(
     610 -    g_vec: np.ndarray,
     611 -    genre_vocab: np.ndarray,
     612 -    *,
     613 -    top_n: int,
     614 -    min_weight: float,
     615 -) -> list[str]:
     616 -    if top_n <= 0:
     617 -        return []
     618 -    if g_vec.size == 0:
     619 -        return []
     620 -    weights = np.array(g_vec, dtype=float)
     621 -    if weights.ndim != 1:
     622 -        weights = weights.reshape(-1)
     623 -    if not np.isfinite(weights).any():
     624 -        return []
     625 -    order = np.argsort(-weights)
     626 -    labels: list[str] = []
     627 -    for idx in order:
     628 -        w = float(weights[int(idx)])
     629 -        if w < float(min_weight):
     630 -            break
     631 -        label = str(genre_vocab[int(idx)])
     632 -        if label:
     633 -            labels.append(label)
     634 -        if len(labels) >= int(top_n):
     635 -            break
     636 -    return labels
     637 -
     638 -
     639 -def _load_genre_similarity_graph(
     640 -    path: Path,
     641 -    *,
     642 -    min_similarity: float,
     643 -) -> dict[str, list[tuple[str, float]]]:
     644 -    try:
     645 -        with path.open("r", encoding="utf-8") as handle:
     646 -            data = yaml.safe_load(handle) or {}
     647 -    except FileNotFoundError:
     648 -        return {}
     649 -    except Exception:
     650 -        logger.warning("Failed to load genre similarity graph from %s", path, exc_info=True)
     651 -        return {}
     652 -    graph: dict[str, list[tuple[str, float]]] = {}
     653 -    for src, neighbors in data.items():
     654 -        if not isinstance(neighbors, dict):
     655 -            continue
     656 -        edges: list[tuple[str, float]] = []
     657 -        for dst, score in neighbors.items():
     658 -            try:
     659 -                sim = float(score)
     660 -            except Exception:
     661 -                continue
     662 -            if sim < float(min_similarity):
     663 -                continue
     664 -            edges.append((str(dst), float(sim)))
     665 -        if edges:
     666 -            graph[str(src)] = edges
     667 -    return graph
     668 -
     669 -
     670 -def _shortest_genre_path(
     671 -    graph: dict[str, list[tuple[str, float]]],
     672 -    start: str,
     673 -    goal: str,
     674 -    *,
     675 -    max_steps: int,
     676 -) -> Optional[list[str]]:
     677 -    start = str(start)
     678 -    goal = str(goal)
     679 -    if start == goal:
     680 -        return [start]
     681 -    if start not in graph or goal not in graph:
     682 -        return None
     683 -    max_steps = max(1, int(max_steps))
     684 -    pq: list[tuple[float, str, list[str]]] = [(0.0, start, [start])]
     685 -    best_cost: dict[str, float] = {start: 0.0}
     686 -    while pq:
     687 -        cost, node, path = heapq.heappop(pq)
     688 -        if node == goal:
     689 -            return path
     690 -        if len(path) - 1 >= max_steps:
     691 -            continue
     692 -        for neighbor, sim in graph.get(node, []):
     693 -            edge_cost = 1.0 - float(sim)
     694 -            next_cost = cost + edge_cost
     695 -            if next_cost >= best_cost.get(neighbor, float("inf")):
     696 -                continue
     697 -            best_cost[neighbor] = next_cost
     698 -            heapq.heappush(pq, (next_cost, neighbor, path + [neighbor]))
     699 -    return None
     700 -
     701 -
     702 -def _label_to_genre_vector(
     703 -    label: str,
     704 -    *,
     705 -    genre_vocab: np.ndarray,
     706 -    genre_vocab_map: dict[str, int],
     707 -) -> Optional[np.ndarray]:
     708 -    idx = genre_vocab_map.get(str(label).strip().lower())
     709 -    if idx is None:
     710 -        return None
     711 -    vec = np.zeros((len(genre_vocab),), dtype=float)
     712 -    vec[int(idx)] = 1.0
     713 -    return vec
     714 -
     715 -
     716 -def _fallback_genre_vector(
     717 -    pier_idx: int,
     718 -    *,
     719 -    X_full_norm: np.ndarray,
     720 -    X_genre_norm: np.ndarray,
     721 -    k: int,
     722 -) -> Optional[np.ndarray]:
     723 -    if k <= 0:
     724 -        return None
     725 -    if X_genre_norm is None:
     726 -        return None
     727 -    sims = np.dot(X_full_norm, X_full_norm[int(pier_idx)])
     728 -    order = np.argsort(-sims)
     729 -    collected = []
     730 -    for idx in order:
     731 -        if int(idx) == int(pier_idx):
     732 -            continue
     733 -        vec = X_genre_norm[int(idx)]
     734 -        if float(np.linalg.norm(vec)) <= 1e-8:
     735 -            continue
     736 -        collected.append(vec)
     737 -        if len(collected) >= int(k):
     738 -            break
     739 -    if not collected:
     740 -        return None
     741 -    avg = np.mean(np.stack(collected, axis=0), axis=0)
     742 -    return _normalize_vec(avg)
     743 -
     744 -
     745 -def _build_genre_targets(
     746 -    *,
     747 -    pier_a: int,
     748 -    pier_b: int,
     749 -    interior_length: int,
     750 -    X_full_norm: np.ndarray,
     751 -    X_genre_norm: np.ndarray,
     752 -    genre_vocab: np.ndarray,
     753 -    genre_graph: Optional[dict[str, list[tuple[str, float]]]],
     754 -    cfg: PierBridgeConfig,
     755 -    warnings: list[dict[str, Any]],
     756 -) -> Optional[list[np.ndarray]]:
     757 -    if interior_length <= 0:
     758 -        return None
     759 -    if X_genre_norm is None:
     760 -        return None
     761 -    g_a = X_genre_norm[pier_a]
     762 -    g_b = X_genre_norm[pier_b]
     763 -    missing = []
     764 -    if float(np.linalg.norm(g_a)) <= 1e-8:
     765 -        fallback = _fallback_genre_vector(
     766 -            pier_a, X_full_norm=X_full_norm, X_genre_norm=X_genre_norm, k=int(cfg.dj_waypoint_fallback_k)
     767 -        )
     768 -        if fallback is not None:
     769 -            g_a = fallback
     770 -            warnings.append({
     771 -                "type": "genre_fallback",
     772 -                "scope": "anchor",
     773 -                "anchor_id": int(pier_a),
     774 -                "fallback": "neighbor_avg",
     775 -                "k": int(cfg.dj_waypoint_fallback_k),
     776 -            })
     777 -        else:
     778 -            missing.append(int(pier_a))
     779 -    if float(np.linalg.norm(g_b)) <= 1e-8:
     780 -        fallback = _fallback_genre_vector(
     781 -            pier_b, X_full_norm=X_full_norm, X_genre_norm=X_genre_norm, k=int(cfg.dj_waypoint_fallback_k)
     782 -        )
     783 -        if fallback is not None:
     784 -            g_b = fallback
     785 -            warnings.append({
     786 -                "type": "genre_fallback",
     787 -                "scope": "anchor",
     788 -                "anchor_id": int(pier_b),
     789 -                "fallback": "neighbor_avg",
     790 -                "k": int(cfg.dj_waypoint_fallback_k),
     791 -            })
     792 -        else:
     793 -            missing.append(int(pier_b))
     794 -    if missing:
     795 -        warnings.append({
     796 -            "type": "genre_missing",
     797 -            "scope": "segment",
     798 -            "message": "Genre guidance reduced because metadata is missing; consider adding genres.",
     799 -            "missing_anchor_indices": missing,
     800 -        })
     801 -        return None
     802 -
     803 -    route_shape = str(cfg.dj_route_shape or "linear").strip().lower()
     804 -    if route_shape not in {"linear", "arc", "ladder"}:
     805 -        route_shape = "linear"
     806 -
     807 -    if route_shape != "ladder" or not genre_graph:
     808 -        g_targets: list[np.ndarray] = []
     809 -        for i in range(int(interior_length)):
     810 -            if route_shape == "arc":
     811 -                frac = _progress_target_curve(i, interior_length, "arc")
     812 -            else:
     813 -                frac = _step_fraction(i, interior_length)
     814 -            g = (1.0 - frac) * g_a + frac * g_b
     815 -            g_targets.append(_normalize_vec(g))
     816 -        return g_targets
     817 -
     818 -    vocab_map = _genre_vocab_map(genre_vocab)
     819 -    labels_a = _select_top_genre_labels(
     820 -        g_a, genre_vocab, top_n=int(cfg.dj_ladder_top_labels), min_weight=float(cfg.dj_ladder_min_label_weight)
     821 -    )
     822 -    labels_b = _select_top_genre_labels(
     823 -        g_b, genre_vocab, top_n=int(cfg.dj_ladder_top_labels), min_weight=float(cfg.dj_ladder_min_label_weight)
     824 -    )
     825 -    if not labels_a or not labels_b:
     826 -        warnings.append({
     827 -            "type": "genre_ladder_unavailable",
     828 -            "scope": "segment",
     829 -            "message": "Genre ladder disabled; falling back to linear drift.",
     830 -        })
     831 -        return _build_genre_targets(
     832 -            pier_a=pier_a,
     833 -            pier_b=pier_b,
     834 -            interior_length=interior_length,
     835 -            X_full_norm=X_full_norm,
     836 -            X_genre_norm=X_genre_norm,
     837 -            genre_vocab=genre_vocab,
     838 -            genre_graph=None,
     839 -            cfg=replace(cfg, dj_route_shape="linear"),
     840 -            warnings=warnings,
     841 -        )
     842 -
     843 -    path_labels = None
     844 -    for la in labels_a:
     845 -        for lb in labels_b:
     846 -            path_labels = _shortest_genre_path(
     847 -                genre_graph,
     848 -                la,
     849 -                lb,
     850 -                max_steps=int(cfg.dj_ladder_max_steps),
     851 -            )
     852 -            if path_labels:
     853 -                break
     854 -        if path_labels:
     855 -            break
     856 -    if not path_labels:
     857 -        warnings.append({
     858 -            "type": "genre_ladder_unavailable",
     859 -            "scope": "segment",
     860 -            "message": "Genre ladder disabled; falling back to linear drift.",
     861 -        })
     862 -        return _build_genre_targets(
     863 -            pier_a=pier_a,
     864 -            pier_b=pier_b,
     865 -            interior_length=interior_length,
     866 -            X_full_norm=X_full_norm,
     867 -            X_genre_norm=X_genre_norm,
     868 -            genre_vocab=genre_vocab,
     869 -            genre_graph=None,
     870 -            cfg=replace(cfg, dj_route_shape="linear"),
     871 -            warnings=warnings,
     872 -        )
     873 -
     874 -    waypoint_vecs: list[np.ndarray] = []
     875 -    for label in path_labels:
     876 -        vec = _label_to_genre_vector(label, genre_vocab=genre_vocab, genre_vocab_map=vocab_map)
     877 -        if vec is not None:
     878 -            waypoint_vecs.append(_normalize_vec(vec))
     879 -    if len(waypoint_vecs) < 2:
     880 -        warnings.append({
     881 -            "type": "genre_ladder_unavailable",
     882 -            "scope": "segment",
     883 -            "message": "Genre ladder disabled; falling back to linear drift.",
     884 -        })
     885 -        return _build_genre_targets(
     886 -            pier_a=pier_a,
     887 -            pier_b=pier_b,
     888 -            interior_length=interior_length,
     889 -            X_full_norm=X_full_norm,
     890 -            X_genre_norm=X_genre_norm,
     891 -            genre_vocab=genre_vocab,
     892 -            genre_graph=None,
     893 -            cfg=replace(cfg, dj_route_shape="linear"),
     894 -            warnings=warnings,
     895 -        )
     896 -
     897 -    g_targets = []
     898 -    steps = int(interior_length)
     899 -    for i in range(steps):
     900 -        frac = _step_fraction(i, steps)
     901 -        scaled = frac * float(len(waypoint_vecs) - 1)
     902 -        idx = int(math.floor(scaled))
     903 -        if idx >= len(waypoint_vecs) - 1:
     904 -            g = waypoint_vecs[-1]
     905 -        else:
     906 -            local = scaled - float(idx)
     907 -            g = (1.0 - local) * waypoint_vecs[idx] + local * waypoint_vecs[idx + 1]
     908 -            g = _normalize_vec(g)
     909 -        g_targets.append(g)
     910 -    return g_targets
     911 -
     912 -
     913 -def _attempt_micro_pier_split(
     914 -    *,
     915 -    pier_a: int,
     916 -    pier_b: int,
     917 -    interior_length: int,
     918 -    candidates: list[int],
     919 -    X_full: np.ndarray,
     920 -    X_full_norm: np.ndarray,
     921 -    X_start: Optional[np.ndarray],
     922 -    X_mid: Optional[np.ndarray],
     923 -    X_end: Optional[np.ndarray],
     924 -    X_genre_norm: Optional[np.ndarray],
     925 -    cfg: PierBridgeConfig,
     926 -    beam_width: int,
     927 -    artist_key_by_idx: Optional[Dict[int, str]],
     928 -    seed_artist_key: Optional[str],
     929 -    recent_global_artists: Optional[List[str]],
     930 -    durations_ms: Optional[np.ndarray],
     931 -    artist_identity_cfg: Optional[ArtistIdentityConfig],
     932 -    bundle: Optional[ArtifactBundle],
     933 -    warnings: list[dict[str, Any]],
     934 -    X_genre_vocab: Optional[np.ndarray],
     935 -    genre_graph: Optional[dict[str, list[tuple[str, float]]]],
     936 -) -> Optional[list[int]]:
     937 -    if interior_length < 2 or not candidates:
     938 -        return None
     939 -    max_micro = max(1, int(cfg.dj_micro_piers_max))
     940 -    topk = max(1, int(cfg.dj_micro_piers_topk))
     941 -
     942 -    vec_a = X_full_norm[pier_a]
     943 -    vec_b = X_full_norm[pier_b]
     944 -    cand_list = [int(i) for i in candidates]
     945 -    sims_a = np.dot(X_full_norm[cand_list], vec_a)
     946 -    sims_b = np.dot(X_full_norm[cand_list], vec_b)
     947 -    bridge_scores = np.minimum(sims_a, sims_b)
     948 -    order = np.argsort(-bridge_scores)
     949 -    micro_candidates = [cand_list[int(i)] for i in order[:topk]]
     950 -
     951 -    left_len = interior_length // 2
     952 -    right_len = interior_length - left_len - 1
     953 -    if right_len < 0:
     954 -        return None
     955 -
     956 -    for micro_idx in micro_candidates[:max_micro]:
     957 -        left_g_targets = None
     958 -        right_g_targets = None
     959 -        if X_genre_norm is not None and X_genre_vocab is not None and bool(cfg.dj_bridging_enabled):
     960 -            left_g_targets = _build_genre_targets(
     961 -                pier_a=pier_a,
     962 -                pier_b=micro_idx,
     963 -                interior_length=left_len,
     964 -                X_full_norm=X_full_norm,
     965 -                X_genre_norm=X_genre_norm,
     966 -                genre_vocab=X_genre_vocab,
     967 -                genre_graph=genre_graph,
     968 -                cfg=cfg,
     969 -                warnings=warnings,
     970 -            )
     971 -            right_g_targets = _build_genre_targets(
     972 -                pier_a=micro_idx,
     973 -                pier_b=pier_b,
     974 -                interior_length=right_len,
     975 -                X_full_norm=X_full_norm,
     976 -                X_genre_norm=X_genre_norm,
     977 -                genre_vocab=X_genre_vocab,
     978 -                genre_graph=genre_graph,
     979 -                cfg=cfg,
     980 -                warnings=warnings,
     981 -            )
     982 -
     983 -        keys_map = dict(artist_key_by_idx or {})
     984 -        if bundle is not None:
     985 -            try:
     986 -                keys_map[int(pier_a)] = identity_keys_for_index(bundle, int(pier_a)).artist_key
     987 -                keys_map[int(pier_b)] = identity_keys_for_index(bundle, int(pier_b)).artist_key
     988 -                keys_map[int(micro_idx)] = identity_keys_for_index(bundle, int(micro_idx)).artist_key
     989 -            except Exception:
     990 -                pass
     991 -
     992 -        left_path, _, _, _ = _beam_search_segment(
     993 -            pier_a,
     994 -            micro_idx,
     995 -            left_len,
     996 -            cand_list,
     997 -            X_full,
     998 -            X_full_norm,
     999 -            X_start,
    1000 -            X_mid,
    1001 -            X_end,
    1002 -            X_genre_norm,
    1003 -            cfg,
    1004 -            beam_width,
    1005 -            artist_key_by_idx=(keys_map if keys_map else None),
    1006 -            seed_artist_key=seed_artist_key,
    1007 -            recent_global_artists=recent_global_artists,
    1008 -            durations_ms=durations_ms,
    1009 -            artist_identity_cfg=artist_identity_cfg,
    1010 -            bundle=bundle,
    1011 -            g_targets_override=left_g_targets,
    1012 -        )
    1013 -        if left_path is None:
    1014 -            continue
    1015 -
    1016 -        used_left = set(int(i) for i in left_path)
    1017 -        right_candidates = [int(i) for i in cand_list if int(i) not in used_left and int(i) != int(micro_idx)]
    1018 -
    1019 -        right_path, _, _, _ = _beam_search_segment(
    1020 -            micro_idx,
    1021 -            pier_b,
    1022 -            right_len,
    1023 -            right_candidates,
    1024 -            X_full,
    1025 -            X_full_norm,
    1026 -            X_start,
    1027 -            X_mid,
    1028 -            X_end,
    1029 -            X_genre_norm,
    1030 -            cfg,
    1031 -            beam_width,
    1032 -            artist_key_by_idx=(keys_map if keys_map else None),
    1033 -            seed_artist_key=seed_artist_key,
    1034 -            recent_global_artists=recent_global_artists,
    1035 -            durations_ms=durations_ms,
    1036 -            artist_identity_cfg=artist_identity_cfg,
    1037 -            bundle=bundle,
    1038 -            g_targets_override=right_g_targets,
    1039 -        )
    1040 -        if right_path is None:
    1041 -            continue
    1042 -
    1043 -        warnings.append({
    1044 -            "type": "micro_pier_used",
    1045 -            "scope": "segment",
    1046 -            "message": "Inserted a micro-pier connector to bridge a difficult segment.",
    1047 -            "micro_pier_index": int(micro_idx),
    1048 -        })
    1049 -        return left_path + [int(micro_idx)] + right_path
    1050 -
    1051 -    return None
    1052 -
    1053 -
    1054 -def _segment_far_stats(
    1055 -    *,
    1056 -    pier_a: int,
    1057 -    pier_b: int,
    1058 -    X_full_norm: np.ndarray,
    1059 -    X_genre_norm: Optional[np.ndarray],
    1060 -    universe: list[int],
    1061 -    used_track_ids: Set[int],
    1062 -    bridge_floor: float,
    1063 -) -> dict[str, Optional[float]]:
    1064 -    sim_sonic = float(np.dot(X_full_norm[pier_a], X_full_norm[pier_b]))
    1065 -    sim_genre = None
    1066 -    if X_genre_norm is not None:
    1067 -        sim_genre = float(np.dot(X_genre_norm[pier_a], X_genre_norm[pier_b]))
    1068 -    available = [int(i) for i in universe if int(i) not in used_track_ids]
    1069 -    scarcity = None
    1070 -    if available:
    1071 -        vec_a = X_full_norm[pier_a]
    1072 -        vec_b = X_full_norm[pier_b]
    1073 -        sims_a = np.dot(X_full_norm[available], vec_a)
    1074 -        sims_b = np.dot(X_full_norm[available], vec_b)
    1075 -        gate = np.minimum(sims_a, sims_b) >= float(bridge_floor)
    1076 -        scarcity = float(np.mean(gate)) if gate.size > 0 else None
    1077 -    return {
    1078 -        "sonic_sim": sim_sonic,
    1079 -        "genre_sim": sim_genre,
    1080 -        "connector_scarcity": scarcity,
    1081 -    }
    1082 -
    1083 -
    1084 -def _order_seeds_by_bridgeability(
    1085 -    seed_indices: List[int],
    1086 -    X_full_norm: np.ndarray,
    1087 -    X_start_norm: Optional[np.ndarray],
    1088 -    X_end_norm: Optional[np.ndarray],
    1089 -    X_genre_norm: Optional[np.ndarray] = None,
    1090 -    *,
    1091 -    weight_sonic: float = 0.0,
    1092 -    weight_genre: float = 0.0,
    1093 -    weight_bridge: float = 1.0,
    1094 -) -> List[int]:
    1095 -    """
    1096 -    Order seed indices to maximize total bridgeability.
    1097 -    For <=6 seeds, evaluates all permutations.
    1098 -    For >6 seeds, uses greedy nearest-neighbor heuristic.
    1099 -    """
    1100 -    n = len(seed_indices)
    1101 -    if n <= 1:
    1102 -        return seed_indices
    1103 -
    1104 -    weight_sonic = float(weight_sonic) if math.isfinite(float(weight_sonic)) else 0.0
    1105 -    weight_genre = float(weight_genre) if math.isfinite(float(weight_genre)) else 0.0
    1106 -    weight_bridge = float(weight_bridge) if math.isfinite(float(weight_bridge)) else 0.0
    1107 -    weight_sonic = max(0.0, weight_sonic)
    1108 -    weight_genre = max(0.0, weight_genre)
    1109 -    weight_bridge = max(0.0, weight_bridge)
    1110 -    total_weight = weight_sonic + weight_genre + weight_bridge
    1111 -    if total_weight <= 1e-9:
    1112 -        weight_bridge = 1.0
    1113 -        total_weight = 1.0
    1114 -    weight_sonic /= total_weight
    1115 -    weight_genre /= total_weight
    1116 -    weight_bridge /= total_weight
    1117 -
    1118 -    def _pair_score(a: int, b: int) -> float:
    1119 -        score = 0.0
    1120 -        if weight_bridge > 0:
    1121 -            score += weight_bridge * _compute_bridgeability_score(
    1122 -                a, b, X_full_norm, X_start_norm, X_end_norm
    1123 -            )
    1124 -        if weight_sonic > 0:
    1125 -            score += weight_sonic * float(np.dot(X_full_norm[a], X_full_norm[b]))
    1126 -        if weight_genre > 0 and X_genre_norm is not None:
    1127 -            score += weight_genre * float(np.dot(X_genre_norm[a], X_genre_norm[b]))
    1128 -        return score
    1129 -
    1130 -    if n <= 6:
    1131 -        # Exhaustive search for small seed counts
    1132 -        best_order = None
    1133 -        best_score = -float('inf')
    1134 -
    1135 -        for perm in itertools.permutations(seed_indices):
    1136 -            total_score = 0.0
    1137 -            for i in range(len(perm) - 1):
    1138 -                total_score += _pair_score(perm[i], perm[i + 1])
    1139 -            if total_score > best_score:
    1140 -                best_score = total_score
    1141 -                best_order = list(perm)
    1142 -
    1143 -        logger.info("Seed ordering: evaluated %d permutations, best_score=%.4f",
    1144 -                   math.factorial(n), best_score)
    1145 -        return best_order or seed_indices
    1146 -    else:
    1147 -        # Greedy nearest-neighbor for larger seed counts
    1148 -        remaining = set(seed_indices)
    1149 -        # Start with the first seed
    1150 -        ordered = [seed_indices[0]]
    1151 -        remaining.remove(seed_indices[0])
    1152 -
    1153 -        while remaining:
    1154 -            current = ordered[-1]
    1155 -            best_next = None
    1156 -            best_score = -float('inf')
    1157 -
    1158 -            for candidate in remaining:
    1159 -                score = _pair_score(current, candidate)
    1160 -                if score > best_score:
    1161 -                    best_score = score
    1162 -                    best_next = candidate
    1163 -
    1164 -            if best_next is not None:
    1165 -                ordered.append(best_next)
    1166 -                remaining.remove(best_next)
    1167 -
    1168 -        logger.info("Seed ordering: greedy heuristic for %d seeds", n)
    1169 -        return ordered
    1170 -
    1171 -
    1172 -def _dedupe_candidate_pool(
    1173 -    pool_indices: List[int],
    1174 -    bundle: ArtifactBundle,
    1175 -) -> Tuple[List[int], Dict[str, int]]:
    1176 -    """
    1177 -    Deduplicate candidate pool by normalized artist+title.
    1178 -    Returns deduplicated indices and mapping of norm_key -> chosen index.
    1179 -
    1180 -    Prefers canonical versions based on version preference scoring.
    1181 -    """
    1182 -    from src.title_dedupe import calculate_version_preference_score
    1183 -
    1184 -    seen: Dict[str, Tuple[int, int]] = {}  # norm_key -> (index, preference_score)
    1185 -
    1186 -    for idx in pool_indices:
    1187 -        keys = identity_keys_for_index(bundle, int(idx))
    1188 -        key = f"{keys.artist_key}|||{keys.title_key}"
    1189 -
    1190 -        # Compute preference score (higher = more canonical)
    1191 -        title = str(bundle.track_titles[idx]) if bundle.track_titles is not None else ""
    1192 -        pref_score = calculate_version_preference_score(title)
    1193 -
    1194 -        if key not in seen or pref_score > seen[key][1]:
    1195 -            seen[key] = (idx, pref_score)
    1196 -
    1197 -    deduped = [idx for idx, _ in seen.values()]
    1198 -    norm_to_idx = {key: idx for key, (idx, _) in seen.items()}
    1199 -
    1200 -    logger.debug("Deduped candidate pool: %d -> %d tracks", len(pool_indices), len(deduped))
    1201 -    return deduped, norm_to_idx
    1202 -
    1203 -
    1204 -def _build_segment_candidate_pool_legacy(
    1205 -    pier_a: int,
    1206 -    pier_b: int,
    1207 -    X_full_norm: np.ndarray,
    1208 -    universe_indices: List[int],
    1209 -    used_track_ids: Set[int],
    1210 -    neighbors_m: int,
    1211 -    bridge_helpers: int,
    1212 -    artist_keys: Optional[np.ndarray] = None,
    1213 -    bridge_floor: float = 0.0,
    1214 -    allowed_set: Optional[Set[int]] = None,
    1215 -    internal_connectors: Optional[Set[int]] = None,
    1216 -    internal_connector_cap: int = 0,
    1217 -    internal_connector_priority: bool = True,
    1218 -    diagnostics: Optional[Dict[str, Any]] = None,
    1219 -) -> List[int]:
    1220 -    """
    1221 -    Legacy segment pool builder (debug/compat).
    1222 -
    1223 -    Builds candidates via a union of:
    1224 -    - Top M neighbors of pier_a by full similarity
    1225 -    - Top M neighbors of pier_b by full similarity
    1226 -    - Top B "bridge helper" tracks by two-sided bridge score
    1227 -    Then dedupes to 1-per-artist and applies the bridge_floor gate.
    1228 -
    1229 -    Includes:
    1230 -    - Top M neighbors of pier_a by full similarity
    1231 -    - Top M neighbors of pier_b by full similarity
    1232 -    - Top B "bridge helper" tracks by two-sided bridge score
    1233 -
    1234 -    Only ONE track per artist is allowed in the segment.
    1235 -    This prevents artist clustering without needing min_gap constraints.
    1236 -    All artists (including seed artist) follow the same one-per-segment rule.
    1237 -    """
    1238 -    # Filter out used tracks
    1239 -    available = [idx for idx in universe_indices if idx not in used_track_ids]
    1240 -    if not available:
    1241 -        if diagnostics is not None:
    1242 -            diagnostics.update(
    1243 -                {
    1244 -                    "available": 0,
    1245 -                    "neighbors_a": 0,
    1246 -                    "neighbors_b": 0,
    1247 -                    "helpers": 0,
    1248 -                    "combined": 0,
    1249 -                    "combined_allowed": 0,
    1250 -                    "deduped": 0,
    1251 -                    "after_bridge_gate": 0,
    1252 -                    "internal_connectors_candidates": 0,
    1253 -                    "internal_connectors_pass_gate": 0,
    1254 -                    "internal_connectors_selected": 0,
    1255 -                    "final": 0,
    1256 -                }
    1257 -            )
    1258 -        return []
    1259 -    if diagnostics is not None:
    1260 -        diagnostics["available"] = len(available)
    1261 -
    1262 -    # Compute similarities to both piers
    1263 -    vec_a = X_full_norm[pier_a]
    1264 -    vec_b = X_full_norm[pier_b]
    1265 -
    1266 -    sim_to_a = {}
    1267 -    sim_to_b = {}
    1268 -    bridge_score = {}
    1269 -
    1270 -    for idx in available:
    1271 -        sim_a = float(np.dot(X_full_norm[idx], vec_a))
    1272 -        sim_b = float(np.dot(X_full_norm[idx], vec_b))
    1273 -        sim_to_a[idx] = sim_a
    1274 -        sim_to_b[idx] = sim_b
    1275 -        # Bridge score: geometric mean of similarities to both piers
    1276 -        bridge_score[idx] = math.sqrt(max(0, sim_a) * max(0, sim_b))
    1277 -
    1278 -    # Top M neighbors of pier_a
    1279 -    sorted_by_a = sorted(available, key=lambda i: sim_to_a[i], reverse=True)
    1280 -    neighbors_a = set(sorted_by_a[:neighbors_m])
    1281 -    if diagnostics is not None:
    1282 -        diagnostics["neighbors_a"] = len(neighbors_a)
    1283 -
    1284 -    # Top M neighbors of pier_b
    1285 -    sorted_by_b = sorted(available, key=lambda i: sim_to_b[i], reverse=True)
    1286 -    neighbors_b = set(sorted_by_b[:neighbors_m])
    1287 -    if diagnostics is not None:
    1288 -        diagnostics["neighbors_b"] = len(neighbors_b)
    1289 -
    1290 -    # Top B bridge helpers
    1291 -    sorted_by_bridge = sorted(available, key=lambda i: bridge_score[i], reverse=True)
    1292 -    helpers = set(sorted_by_bridge[:bridge_helpers])
    1293 -    if diagnostics is not None:
    1294 -        diagnostics["helpers"] = len(helpers)
    1295 -
    1296 -    # Combine all candidates
    1297 -    combined = neighbors_a | neighbors_b | helpers
    1298 -    if diagnostics is not None:
    1299 -        diagnostics["combined"] = len(combined)
    1300 -
    1301 -    # Internal connectors (optional priority/cap)
    1302 -    connector_selected: List[int] = []
    1303 -    connector_candidates = 0
    1304 -    connector_pass_gate = 0
    1305 -    if internal_connectors:
    1306 -        for idx in internal_connectors:
    1307 -            if idx in used_track_ids or (allowed_set is not None and idx not in allowed_set):
    1308 -                continue
    1309 -            connector_candidates += 1
    1310 -            sim_a = float(np.dot(X_full_norm[idx], vec_a))
    1311 -            sim_b = float(np.dot(X_full_norm[idx], vec_b))
    1312 -            if min(sim_a, sim_b) < bridge_floor:
    1313 -                continue
    1314 -            connector_pass_gate += 1
    1315 -            connector_selected.append(idx)
    1316 -        connector_selected = connector_selected[: internal_connector_cap if internal_connector_cap > 0 else len(connector_selected)]
    1317 -    if diagnostics is not None:
    1318 -        diagnostics["internal_connectors_candidates"] = int(connector_candidates)
    1319 -        diagnostics["internal_connectors_pass_gate"] = int(connector_pass_gate)
    1320 -        diagnostics["internal_connectors_selected"] = int(len(connector_selected))
    1321 -
    1322 -    # Dedupe to ONE track per artist (all artists treated equally, including seed artist)
    1323 -    if artist_keys is not None:
    1324 -        artist_best: Dict[str, Tuple[int, float]] = {}  # artist -> (idx, score)
    1325 -        combined_allowed = 0
    1326 -        for idx in combined:
    1327 -            if allowed_set is not None and idx not in allowed_set:
    1328 -                continue
    1329 -            combined_allowed += 1
    1330 -            artist = normalize_artist_key(str(artist_keys[idx]))
    1331 -            score = bridge_score.get(idx, 0.0)
    1332 -
    1333 -            if artist not in artist_best or score > artist_best[artist][1]:
    1334 -                artist_best[artist] = (idx, score)
    1335 -
    1336 -        # Build final pool: one track per artist (normalized)
    1337 -        deduped: List[int] = [idx for idx, _ in artist_best.values()]
    1338 -        if diagnostics is not None:
    1339 -            diagnostics["combined_allowed"] = int(combined_allowed)
    1340 -            diagnostics["deduped"] = int(len(deduped))
    1341 -
    1342 -        logger.debug("Segment pool: %d combined -> %d after 1-per-artist dedupe",
    1343 -                     len(combined), len(deduped))
    1344 -        filtered = [
    1345 -            idx for idx in deduped
    1346 -            if min(float(np.dot(X_full_norm[idx], vec_a)), float(np.dot(X_full_norm[idx], vec_b))) >= bridge_floor
    1347 -        ]
    1348 -        if diagnostics is not None:
    1349 -            diagnostics["after_bridge_gate"] = int(len(filtered))
    1350 -    else:
    1351 -        filtered = [
    1352 -            idx for idx in combined
    1353 -            if min(float(np.dot(X_full_norm[idx], vec_a)), float(np.dot(X_full_norm[idx], vec_b))) >= bridge_floor
    1354 -            and (allowed_set is None or idx in allowed_set)
    1355 -        ]
    1356 -        if diagnostics is not None:
    1357 -            diagnostics["combined_allowed"] = int(
    1358 -                sum(1 for idx in combined if (allowed_set is None or idx in allowed_set))
    1359 -            )
    1360 -            diagnostics["deduped"] = int(len(combined))
    1361 -            diagnostics["after_bridge_gate"] = int(len(filtered))
    1362 -
    1363 -    if internal_connector_priority:
    1364 -        filtered = list(dict.fromkeys(connector_selected + filtered))
    1365 -    else:
    1366 -        filtered = list(dict.fromkeys(filtered + connector_selected))
    1367 -    if diagnostics is not None:
    1368 -        diagnostics["final"] = int(len(filtered))
    1369 -    return filtered
    1370 -
    1371 -
    1372 -def _compute_bridge_score(
    1373 -    sim_a: float,
    1374 -    sim_b: float,
    1375 -    *,
    1376 -    experiment_enabled: bool,
    1377 -    experiment_min_weight: float,
    1378 -    experiment_balance_weight: float,
    1379 -) -> float:
    1380 -    denom = sim_a + sim_b
    1381 -    hmean = 0.0 if denom <= 1e-9 else (2.0 * sim_a * sim_b) / denom
    1382 -    if not experiment_enabled:
    1383 -        return float(hmean)
    1384 -
    1385 -    min_weight = max(0.0, min(1.0, float(experiment_min_weight)))
    1386 -    balance_weight = max(0.0, min(1.0 - min_weight, float(experiment_balance_weight)))
    1387 -    hmean_weight = max(0.0, 1.0 - min_weight - balance_weight)
    1388 -
    1389 -    min_sim = min(sim_a, sim_b)
    1390 -    balance = 1.0 - abs(sim_a - sim_b)
    1391 -    if balance < 0.0:
    1392 -        balance = 0.0
    1393 -    elif balance > 1.0:
    1394 -        balance = 1.0
    1395 -
    1396 -    return float(
    1397 -        (hmean_weight * hmean)
    1398 -        + (min_weight * min_sim)
    1399 -        + (balance_weight * balance)
    1400 -    )
    1401 -
    1402 -
    1403 -def _build_segment_candidate_pool_scored(
    1404 -    *,
    1405 -    pier_a: int,
    1406 -    pier_b: int,
    1407 -    X_full_norm: np.ndarray,
    1408 -    universe_indices: List[int],
    1409 -    used_track_ids: Set[int],
    1410 -    bundle: ArtifactBundle,
    1411 -    bridge_floor: float,
    1412 -    segment_pool_max: int,
    1413 -    allowed_set: Optional[Set[int]] = None,
    1414 -    internal_connectors: Optional[Set[int]] = None,
    1415 -    internal_connector_cap: int = 0,
    1416 -    internal_connector_priority: bool = True,
    1417 -    seed_artist_key: Optional[str] = None,
    1418 -    disallow_pier_artists_in_interiors: bool = False,
    1419 -    disallow_seed_artist_in_interiors: bool = False,
    1420 -    used_track_keys: Optional[Set[tuple[str, str]]] = None,
    1421 -    seed_track_keys: Optional[Set[tuple[str, str]]] = None,
    1422 -    diagnostics: Optional[Dict[str, Any]] = None,
    1423 -    experiment_bridge_scoring_enabled: bool = False,
    1424 -    experiment_bridge_min_weight: float = 0.25,
    1425 -    experiment_bridge_balance_weight: float = 0.15,
    1426 -) -> tuple[List[int], Dict[int, str], Dict[int, str]]:
    1427 -    """
    1428 -    Segment-local candidate pool builder ("segment_scored").
    1429 -
    1430 -    Builds a segment candidate pool by scoring candidates jointly vs BOTH endpoints (pier A and pier B),
    1431 -    applying structural exclusions (used ids, allowed-set clamp, artist policies, track_key collisions),
    1432 -    gating by bridge_floor, then taking top-K by harmonic_mean(simA, simB).
    1433 -
    1434 -    Returns:
    1435 -      - candidates: list[int] indices for beam search
    1436 -      - artist_key_by_idx: mapping for candidates (robust identity key)
    1437 -      - title_key_by_idx: mapping for candidates (normalized title key)
    1438 -    """
    1439 -    segment_pool_max = int(max(0, segment_pool_max))
    1440 -    if segment_pool_max <= 0:
    1441 -        if diagnostics is not None:
    1442 -            diagnostics.update(
    1443 -                {
    1444 -                    "pool_strategy": "segment_scored",
    1445 -                    "base_universe": int(len(universe_indices)),
    1446 -                    "excluded_used_track_ids": 0,
    1447 -                    "excluded_allowed_set": 0,
    1448 -                    "excluded_seed_artist_policy": 0,
    1449 -                    "excluded_pier_artist_policy": 0,
    1450 -                    "excluded_track_key_collision": 0,
    1451 -                    "excluded_track_key_collision_with_piers": 0,
    1452 -                    "eligible_after_structural": 0,
    1453 -                    "below_bridge_floor": 0,
    1454 -                    "pass_bridge_floor": 0,
    1455 -                    "collapsed_by_artist_key": 0,
    1456 -                    "selected_external": 0,
    1457 -                    "internal_connectors_candidates": 0,
    1458 -                    "internal_connectors_pass_gate": 0,
    1459 -                    "internal_connectors_selected": 0,
    1460 -                    "final": 0,
    1461 -                    "segment_pool_max": int(segment_pool_max),
    1462 -                    "bridge_score_mode": (
    1463 -                        "experimental"
    1464 -                        if experiment_bridge_scoring_enabled
    1465 -                        else "hmean"
    1466 -                    ),
    1467 -                }
    1468 -            )
    1469 -        return [], {}, {}
    1470 -
    1471 -    used_track_keys = used_track_keys or set()
    1472 -    seed_track_keys = seed_track_keys or set()
    1473 -
    1474 -    # Endpoint artist keys (robust identity), for optional policies
    1475 -    pier_a_artist_key = identity_keys_for_index(bundle, pier_a).artist_key
    1476 -    pier_b_artist_key = identity_keys_for_index(bundle, pier_b).artist_key
    1477 -
    1478 -    excluded_used = 0
    1479 -    excluded_allowed = 0
    1480 -    excluded_seed_artist = 0
    1481 -    excluded_pier_artist = 0
    1482 -    excluded_track_key = 0
    1483 -    excluded_track_key_with_piers = 0
    1484 -
    1485 -    artist_key_by_idx: Dict[int, str] = {}
    1486 -    title_key_by_idx: Dict[int, str] = {}
    1487 -
    1488 -    # Structural filtering (segment-local): used ids, allowed-set clamp, policies, track_key collisions
    1489 -    structural: List[int] = []
    1490 -    for idx in universe_indices:
    1491 -        i = int(idx)
    1492 -        if i in used_track_ids:
    1493 -            excluded_used += 1
    1494 -            continue
    1495 -        if allowed_set is not None and i not in allowed_set:
    1496 -            excluded_allowed += 1
    1497 -            continue
    1498 -
    1499 -        keys = identity_keys_for_index(bundle, i)
    1500 -        ak = keys.artist_key
    1501 -        tk = keys.title_key
    1502 -        artist_key_by_idx[i] = ak
    1503 -        title_key_by_idx[i] = tk
    1504 -
    1505 -        if disallow_seed_artist_in_interiors and seed_artist_key and ak == seed_artist_key:
    1506 -            excluded_seed_artist += 1
    1507 -            continue
    1508 -        if disallow_pier_artists_in_interiors and ak in {pier_a_artist_key, pier_b_artist_key}:
    1509 -            excluded_pier_artist += 1
    1510 -            continue
    1511 -
    1512 -        if keys.track_key in used_track_keys:
    1513 -            excluded_track_key += 1
    1514 -            if keys.track_key in seed_track_keys:
    1515 -                excluded_track_key_with_piers += 1
    1516 -            continue
    1517 -
    1518 -        structural.append(i)
    1519 -
    1520 -    if not structural:
    1521 -        if diagnostics is not None:
    1522 -            diagnostics.update(
    1523 -                {
    1524 -                    "pool_strategy": "segment_scored",
    1525 -                    "base_universe": int(len(universe_indices)),
    1526 -                    "excluded_used_track_ids": int(excluded_used),
    1527 -                    "excluded_allowed_set": int(excluded_allowed),
    1528 -                    "excluded_seed_artist_policy": int(excluded_seed_artist),
    1529 -                    "excluded_pier_artist_policy": int(excluded_pier_artist),
    1530 -                    "excluded_track_key_collision": int(excluded_track_key),
    1531 -                    "excluded_track_key_collision_with_piers": int(excluded_track_key_with_piers),
    1532 -                    "eligible_after_structural": 0,
    1533 -                    "below_bridge_floor": 0,
    1534 -                    "pass_bridge_floor": 0,
    1535 -                    "collapsed_by_artist_key": 0,
    1536 -                    "selected_external": 0,
    1537 -                    "internal_connectors_candidates": 0,
    1538 -                    "internal_connectors_pass_gate": 0,
    1539 -                    "internal_connectors_selected": 0,
    1540 -                    "final": 0,
    1541 -                    "segment_pool_max": int(segment_pool_max),
    1542 -                }
    1543 -            )
    1544 -        return [], {}, {}
    1545 -
    1546 -    sim_to_a = np.dot(X_full_norm, X_full_norm[pier_a])
    1547 -    sim_to_b = np.dot(X_full_norm, X_full_norm[pier_b])
    1548 -
    1549 -    below_bridge_floor = 0
    1550 -    passing: List[int] = []
    1551 -    bridge_sim: Dict[int, float] = {}
    1552 -    for i in structural:
    1553 -        sim_a = float(sim_to_a[i])
    1554 -        sim_b = float(sim_to_b[i])
    1555 -        if min(sim_a, sim_b) < float(bridge_floor):
    1556 -            below_bridge_floor += 1
    1557 -            continue
    1558 -        bridge_sim[i] = _compute_bridge_score(
    1559 -            sim_a,
    1560 -            sim_b,
    1561 -            experiment_enabled=bool(experiment_bridge_scoring_enabled),
    1562 -            experiment_min_weight=float(experiment_bridge_min_weight),
    1563 -            experiment_balance_weight=float(experiment_bridge_balance_weight),
    1564 -        )
    1565 -        passing.append(i)
    1566 -
    1567 -    # Rank by bridge_sim (two-sided), then apply 1-per-artist_key within the segment.
    1568 -    passing_sorted = sorted(passing, key=lambda i: (-float(bridge_sim.get(i, 0.0)), int(i)))
    1569 -
    1570 -    # Internal connectors (optional; still gated + policy-checked)
    1571 -    internal_candidates = 0
    1572 -    internal_pass_gate = 0
    1573 -    internal_selected: List[int] = []
    1574 -    internal_ranked: List[tuple[float, int]] = []
    1575 -    if internal_connectors:
    1576 -        for idx in internal_connectors:
    1577 -            i = int(idx)
    1578 -            if i in used_track_ids:
    1579 -                continue
    1580 -            if allowed_set is not None and i not in allowed_set:
    1581 -                continue
    1582 -            keys = identity_keys_for_index(bundle, i)
    1583 -            ak = keys.artist_key
    1584 -            tk = keys.title_key
    1585 -            artist_key_by_idx[i] = ak
    1586 -            title_key_by_idx[i] = tk
    1587 -
    1588 -            if disallow_seed_artist_in_interiors and seed_artist_key and ak == seed_artist_key:
    1589 -                continue
    1590 -            if disallow_pier_artists_in_interiors and ak in {pier_a_artist_key, pier_b_artist_key}:
    1591 -                continue
    1592 -            if keys.track_key in used_track_keys:
    1593 -                continue
    1594 -
    1595 -            internal_candidates += 1
    1596 -            sim_a = float(sim_to_a[i])
    1597 -            sim_b = float(sim_to_b[i])
    1598 -            if min(sim_a, sim_b) < float(bridge_floor):
    1599 -                continue
    1600 -            internal_pass_gate += 1
    1601 -            score = _compute_bridge_score(
    1602 -                sim_a,
    1603 -                sim_b,
    1604 -                experiment_enabled=bool(experiment_bridge_scoring_enabled),
    1605 -                experiment_min_weight=float(experiment_bridge_min_weight),
    1606 -                experiment_balance_weight=float(experiment_bridge_balance_weight),
    1607 -            )
    1608 -            internal_ranked.append((float(score), i))
    1609 -        internal_ranked.sort(key=lambda t: (-t[0], t[1]))
    1610 -
    1611 -    selected_external: List[int] = []
    1612 -    collapsed_by_artist = 0
    1613 -
    1614 -    if internal_connector_priority:
    1615 -        # Select internal connectors first, then fill from external candidates.
    1616 -        used_artists: Set[str] = set()
    1617 -        cap = int(internal_connector_cap) if int(internal_connector_cap) > 0 else len(internal_ranked)
    1618 -        for _score, i in internal_ranked:
    1619 -            ak = artist_key_by_idx.get(i) or identity_keys_for_index(bundle, i).artist_key
    1620 -            if ak in used_artists:
    1621 -                continue
    1622 -            internal_selected.append(i)
    1623 -            used_artists.add(ak)
    1624 -            if len(internal_selected) >= cap:
    1625 -                break
    1626 -
    1627 -        for i in passing_sorted:
    1628 -            ak = artist_key_by_idx.get(i) or identity_keys_for_index(bundle, i).artist_key
    1629 -            if ak in used_artists:
    1630 -                collapsed_by_artist += 1
    1631 -                continue
    1632 -            used_artists.add(ak)
    1633 -            selected_external.append(i)
    1634 -            if len(selected_external) >= int(segment_pool_max):
    1635 -                break
    1636 -        combined = list(dict.fromkeys(internal_selected + selected_external))
    1637 -    else:
    1638 -        # Select external first, then add internal connectors up to cap.
    1639 -        used_artists = set()
    1640 -        for i in passing_sorted:
    1641 -            ak = artist_key_by_idx.get(i) or identity_keys_for_index(bundle, i).artist_key
    1642 -            if ak in used_artists:
    1643 -                collapsed_by_artist += 1
    1644 -                continue
    1645 -            used_artists.add(ak)
    1646 -            selected_external.append(i)
    1647 -            if len(selected_external) >= int(segment_pool_max):
    1648 -                break
    1649 -
    1650 -        cap = int(internal_connector_cap) if int(internal_connector_cap) > 0 else len(internal_ranked)
    1651 -        for _score, i in internal_ranked:
    1652 -            ak = artist_key_by_idx.get(i) or identity_keys_for_index(bundle, i).artist_key
    1653 -            if ak in used_artists:
    1654 -                continue
    1655 -            internal_selected.append(i)
    1656 -            used_artists.add(ak)
    1657 -            if len(internal_selected) >= cap:
    1658 -                break
    1659 -        combined = list(dict.fromkeys(selected_external + internal_selected))
    1660 -
    1661 -    if diagnostics is not None:
    1662 -        diagnostics.update(
    1663 -            {
    1664 -                "pool_strategy": "segment_scored",
    1665 -                "base_universe": int(len(universe_indices)),
    1666 -                "excluded_used_track_ids": int(excluded_used),
    1667 -                "excluded_allowed_set": int(excluded_allowed),
    1668 -                "excluded_seed_artist_policy": int(excluded_seed_artist),
    1669 -                "excluded_pier_artist_policy": int(excluded_pier_artist),
    1670 -                "excluded_track_key_collision": int(excluded_track_key),
    1671 -                "excluded_track_key_collision_with_piers": int(excluded_track_key_with_piers),
    1672 -                "eligible_after_structural": int(len(structural)),
    1673 -                "below_bridge_floor": int(below_bridge_floor),
    1674 -                "pass_bridge_floor": int(len(passing)),
    1675 -                "collapsed_by_artist_key": int(collapsed_by_artist),
    1676 -                "selected_external": int(len(selected_external)),
    1677 -                "internal_connectors_candidates": int(internal_candidates),
    1678 -                "internal_connectors_pass_gate": int(internal_pass_gate),
    1679 -                "internal_connectors_selected": int(len(internal_selected)),
    1680 -                "final": int(len(combined)),
    1681 -                "segment_pool_max": int(segment_pool_max),
    1682 -            }
    1683 -        )
    1684 -
    1685 -    # Only return mappings for indices in the final candidate list (beam search scope)
    1686 -    artist_key_final = {i: artist_key_by_idx.get(i, "") for i in combined}
    1687 -    title_key_final = {i: title_key_by_idx.get(i, "") for i in combined}
    1688 -    return combined, artist_key_final, title_key_final
    1689 -
    1690 -
    1691 -@dataclass
    1692 -class BeamState:
    1693 -    """State for beam search."""
    1694 -    path: List[int]
    1695 -    score: float
    1696 -    used: Set[int]
    1697 -    used_artists: Set[str] = field(default_factory=set)
    1698 -    last_progress: float = 0.0
    1699 -
    1700 -
    1701 -def _compute_duration_penalty(
    1702 -    candidate_duration_ms: float,
    1703 -    reference_duration_ms: float,
    1704 -    weight: float,
    1705 -) -> float:
    1706 -    """
    1707 -    Compute asymmetric duration penalty based on percentage excess over reference track.
    1708 -
    1709 -    Uses a three-phase geometric curve:
    1710 -    - 0-20% excess: Gentle penalties (barely noticeable)
    1711 -    - 20-50% excess: Moderate increasing penalties
    1712 -    - 50-100% excess: Steep penalties
    1713 -    - >100% excess: Severe penalties (track is 2x+ longer than reference)
    1714 -
    1715 -    Args:
    1716 -        candidate_duration_ms: Candidate track duration in milliseconds
    1717 -        reference_duration_ms: Reference duration (max of two piers) in milliseconds
    1718 -        weight: Penalty weight (default 0.30, range typically 0.10-0.50)
    1719 -
    1720 -    Returns:
    1721 -        Penalty value (>= 0) to subtract from combined_score
    1722 -
    1723 -    Examples:
    1724 -        With weight=0.30 and reference=200s:
    1725 -        - 210s (+5% = +10s): penalty ≈ 0.003 (negligible)
    1726 -        - 240s (+20% = +40s): penalty ≈ 0.015 (gentle)
    1727 -        - 280s (+40% = +80s): penalty ≈ 0.10 (moderate)
    1728 -        - 360s (+80% = +160s): penalty ≈ 0.45 (steep)
    1729 -        - 400s (+100% = +200s): penalty ≈ 0.75 (severe threshold)
    1730 -        - 600s (+200% = +400s): penalty ≈ 3.0 (very severe!)
    1731 -    """
    1732 -    if candidate_duration_ms <= 0 or reference_duration_ms <= 0:
    1733 -        return 0.0
    1734 -
    1735 -    if candidate_duration_ms <= reference_duration_ms:
    1736 -        return 0.0  # No penalty for shorter or equal-length tracks
    1737 -
    1738 -    # Calculate excess as percentage of reference
    1739 -    excess_ratio = (candidate_duration_ms - reference_duration_ms) / reference_duration_ms
    1740 -
    1741 -    # Three-phase geometric penalty curve
    1742 -    if excess_ratio <= 0.20:
    1743 -        # Phase 1 (0-20%): Gentle - power 1.5 for sub-linear growth
    1744 -        # At 20%: penalty = weight * 0.05
    1745 -        penalty = weight * 0.05 * (excess_ratio / 0.20) ** 1.5
    1746 -
    1747 -    elif excess_ratio <= 0.50:
    1748 -        # Phase 2 (20-50%): Moderate - power 2.0 for quadratic growth
    1749 -        # At 20%: ~0.015, At 50%: ~0.30
    1750 -        phase_ratio = (excess_ratio - 0.20) / 0.30
    1751 -        penalty = weight * 0.05 + weight * 0.25 * (phase_ratio ** 2.0)
    1752 -
    1753 -    elif excess_ratio <= 1.00:
    1754 -        # Phase 3 (50-100%): Steep - power 2.5 for accelerating growth
    1755 -        # At 50%: ~0.30, At 100%: ~0.75
    1756 -        phase_ratio = (excess_ratio - 0.50) / 0.50
    1757 -        penalty = weight * 0.30 + weight * 0.45 * (phase_ratio ** 2.5)
    1758 -
    1759 -    else:
    1760 -        # Phase 4 (>100%): Severe - power 3.0 for very steep growth
    1761 -        # At 100%: 0.75, At 200%: 3.0, At 300%: 9.0
    1762 -        phase_ratio = excess_ratio - 1.00
    1763 -        penalty = weight * 0.75 + weight * 2.25 * (phase_ratio ** 3.0)
    1764 -
    1765 -    return penalty
    1766 -
    1767 -
    1768 -def _beam_search_segment(
    1769 -    pier_a: int,
    1770 -    pier_b: int,
    1771 -    interior_length: int,
    1772 -    candidates: List[int],
    1773 -    X_full: np.ndarray,
    1774 -    X_full_norm: np.ndarray,
    1775 -    X_start: Optional[np.ndarray],
    1776 -    X_mid: Optional[np.ndarray],
    1777 -    X_end: Optional[np.ndarray],
    1778 -    X_genre_norm: Optional[np.ndarray],
    1779 -    cfg: PierBridgeConfig,
    1780 -    beam_width: int,
    1781 -    *,
    1782 -    artist_key_by_idx: Optional[Dict[int, str]] = None,
    1783 -    seed_artist_key: Optional[str] = None,
    1784 -    recent_global_artists: Optional[List[str]] = None,
    1785 -    durations_ms: Optional[np.ndarray] = None,
    1786 -    artist_identity_cfg: Optional[ArtistIdentityConfig] = None,
    1787 -    bundle: Optional[ArtifactBundle] = None,
    1788 -    arc_stats: Optional[Dict[str, Any]] = None,
    1789 -    genre_cache_stats: Optional[Dict[str, int]] = None,
    1790 -    g_targets_override: Optional[List[np.ndarray]] = None,
    1791 -) -> Tuple[Optional[List[int]], int, int, Optional[str]]:
    1792 -    """
    1793 -    Constrained beam search to find path from pier_a to pier_b.
    1794 -
    1795 -    Returns interior track indices (not including piers) or None if no path found.
    1796 -
    1797 -    Args:
    1798 -        recent_global_artists: Artist keys from the last min_gap positions of the
    1799 -            global playlist prefix (from previous segments). Used to enforce
    1800 -            cross-segment min_gap constraints during generation. If artist_identity_cfg
    1801 -            is enabled, these are identity keys (collapsing ensemble variants).
    1802 -        durations_ms: Optional array of track durations in milliseconds (parallel to bundle.track_ids)
    1803 -        artist_identity_cfg: Optional config for artist identity resolution (ensemble collapsing)
    1804 -        bundle: Optional bundle for resolving artist strings to identity keys
    1805 -    """
    1806 -
    1807 -    genre_penalty_hits = 0
    1808 -    edges_scored = 0
    1809 -    penalty_strength = float(cfg.genre_penalty_strength)
    1810 -    if not math.isfinite(penalty_strength):
    1811 -        penalty_strength = 0.0
    1812 -    penalty_strength = float(max(0.0, min(1.0, penalty_strength)))
    1813 -    penalty_threshold = float(cfg.genre_penalty_threshold)
    1814 -    genre_tie_break_band = cfg.genre_tie_break_band
    1815 -    if isinstance(genre_tie_break_band, (int, float)) and math.isfinite(float(genre_tie_break_band)):
    1816 -        genre_tie_break_band = float(genre_tie_break_band)
    1817 -        if genre_tie_break_band <= 0:
    1818 -            genre_tie_break_band = None
    1819 -    else:
    1820 -        genre_tie_break_band = None
    1821 -
    1822 -    waypoint_enabled = bool(cfg.dj_bridging_enabled) and X_genre_norm is not None
    1823 -    waypoint_weight = float(cfg.dj_waypoint_weight)
    1824 -    if not math.isfinite(waypoint_weight):
    1825 -        waypoint_weight = 0.0
    1826 -    waypoint_floor = float(cfg.dj_waypoint_floor)
    1827 -    if not math.isfinite(waypoint_floor):
    1828 -        waypoint_floor = 0.0
    1829 -    waypoint_penalty = float(cfg.dj_waypoint_penalty)
    1830 -    if not math.isfinite(waypoint_penalty):
    1831 -        waypoint_penalty = 0.0
    1832 -    waypoint_cap = float(cfg.dj_waypoint_cap)
    1833 -    if not math.isfinite(waypoint_cap):
    1834 -        waypoint_cap = 0.0
    1835 -    waypoint_cap = float(max(0.0, waypoint_cap))
    1836 -    waypoint_tie_break_band = cfg.dj_waypoint_tie_break_band
    1837 -    if isinstance(waypoint_tie_break_band, (int, float)) and math.isfinite(float(waypoint_tie_break_band)):
    1838 -        waypoint_tie_break_band = float(waypoint_tie_break_band)
    1839 -        if waypoint_tie_break_band <= 0:
    1840 -            waypoint_tie_break_band = None
    1841 -    else:
    1842 -        waypoint_tie_break_band = None
    1843 -
    1844 -    g_targets: Optional[List[np.ndarray]] = None
    1845 -    if waypoint_enabled and interior_length > 0:
    1846 -        if g_targets_override is not None and len(g_targets_override) == int(interior_length):
    1847 -            g_targets = g_targets_override
    1848 -        else:
    1849 -            g_a = X_genre_norm[pier_a]
    1850 -            g_b = X_genre_norm[pier_b]
    1851 -            if float(np.linalg.norm(g_a)) <= 1e-8 or float(np.linalg.norm(g_b)) <= 1e-8:
    1852 -                waypoint_enabled = False
    1853 -            else:
    1854 -                g_targets = []
    1855 -                for i in range(interior_length):
    1856 -                    frac = _step_fraction(i, interior_length)
    1857 -                    g = (1.0 - frac) * g_a + frac * g_b
    1858 -                    norm = float(np.linalg.norm(g))
    1859 -                    if norm <= 1e-12:
    1860 -                        g = g_a
    1861 -                    else:
    1862 -                        g = g / norm
    1863 -                    g_targets.append(g)
    1864 -    if waypoint_weight <= 0 and waypoint_penalty <= 0:
    1865 -        waypoint_enabled = False
    1866 -
    1867 -    def _waypoint_delta(sim: Optional[float]) -> float:
    1868 -        if sim is None or not math.isfinite(float(sim)):
    1869 -            return 0.0
    1870 -        delta = float(waypoint_weight) * float(sim)
    1871 -        if waypoint_cap > 0:
    1872 -            delta = float(max(-waypoint_cap, min(waypoint_cap, delta)))
    1873 -        if waypoint_penalty > 0 and waypoint_floor > 0 and float(sim) < waypoint_floor:
    1874 -            penalty = waypoint_penalty * (waypoint_floor - float(sim))
    1875 -            if waypoint_cap > 0:
    1876 -                penalty = min(waypoint_cap, penalty)
    1877 -            delta -= float(penalty)
    1878 -        return float(delta)
    1879 -
    1880 -    if interior_length == 0:
    1881 -        # Check if direct transition meets floor
    1882 -        direct_score = _compute_transition_score(
    1883 -            pier_a, pier_b, X_full, X_start, X_mid, X_end, cfg
    1884 -        )
    1885 -        edges_scored = 1
    1886 -        if direct_score >= cfg.transition_floor:
    1887 -            return [], 0, edges_scored, None
    1888 -        else:
    1889 -            return None, 0, edges_scored, f"direct transition below floor ({direct_score:.3f} < {cfg.transition_floor:.3f})"
    1890 -
    1891 -    # Progress model (A→B) in sonic similarity space (X_full_norm).
    1892 -    progress_active = bool(cfg.progress_enabled)
    1893 -    progress_eps = float(cfg.progress_monotonic_epsilon) if math.isfinite(float(cfg.progress_monotonic_epsilon)) else 0.0
    1894 -    progress_eps = float(max(0.0, progress_eps))
    1895 -    progress_weight = float(cfg.progress_penalty_weight) if math.isfinite(float(cfg.progress_penalty_weight)) else 0.0
    1896 -    progress_weight = float(max(0.0, progress_weight))
    1897 -
    1898 -    progress_arc_enabled = bool(cfg.progress_arc_enabled)
    1899 -    progress_arc_weight = float(cfg.progress_arc_weight)
    1900 -    if not math.isfinite(progress_arc_weight):
    1901 -        progress_arc_weight = 0.0
    1902 -    progress_arc_weight = float(max(0.0, progress_arc_weight))
    1903 -    progress_arc_shape = str(cfg.progress_arc_shape or "linear").strip().lower()
    1904 -    if progress_arc_shape not in {"linear", "arc"}:
    1905 -        progress_arc_shape = "linear"
    1906 -    progress_arc_tolerance = float(cfg.progress_arc_tolerance)
    1907 -    if not math.isfinite(progress_arc_tolerance):
    1908 -        progress_arc_tolerance = 0.0
    1909 -    progress_arc_tolerance = float(max(0.0, progress_arc_tolerance))
    1910 -    progress_arc_loss = str(cfg.progress_arc_loss or "abs").strip().lower()
    1911 -    if progress_arc_loss not in {"abs", "squared", "huber"}:
    1912 -        progress_arc_loss = "abs"
    1913 -    progress_arc_huber_delta = float(cfg.progress_arc_huber_delta)
    1914 -    if not math.isfinite(progress_arc_huber_delta) or progress_arc_huber_delta <= 0:
    1915 -        progress_arc_huber_delta = 0.10
    1916 -    progress_arc_max_step = cfg.progress_arc_max_step
    1917 -    if isinstance(progress_arc_max_step, (int, float)) and math.isfinite(float(progress_arc_max_step)):
    1918 -        progress_arc_max_step = float(progress_arc_max_step)
    1919 -        if progress_arc_max_step <= 0:
    1920 -            progress_arc_max_step = None
    1921 -    else:
    1922 -        progress_arc_max_step = None
    1923 -    progress_arc_max_step_mode = str(cfg.progress_arc_max_step_mode or "penalty").strip().lower()
    1924 -    if progress_arc_max_step_mode not in {"penalty", "gate"}:
    1925 -        progress_arc_max_step_mode = "penalty"
    1926 -    progress_arc_max_step_penalty = float(cfg.progress_arc_max_step_penalty)
    1927 -    if not math.isfinite(progress_arc_max_step_penalty):
    1928 -        progress_arc_max_step_penalty = 0.0
    1929 -    progress_arc_max_step_penalty = float(max(0.0, progress_arc_max_step_penalty))
    1930 -    progress_arc_autoscale_enabled = bool(cfg.progress_arc_autoscale_enabled)
    1931 -    progress_arc_autoscale_min_distance = float(cfg.progress_arc_autoscale_min_distance)
    1932 -    if not math.isfinite(progress_arc_autoscale_min_distance):
    1933 -        progress_arc_autoscale_min_distance = 0.0
    1934 -    progress_arc_autoscale_min_distance = float(max(0.0, progress_arc_autoscale_min_distance))
    1935 -    progress_arc_autoscale_distance_scale = float(cfg.progress_arc_autoscale_distance_scale)
    1936 -    if not math.isfinite(progress_arc_autoscale_distance_scale) or progress_arc_autoscale_distance_scale <= 0:
    1937 -        progress_arc_autoscale_distance_scale = 0.0
    1938 -    progress_arc_autoscale_per_step_scale = bool(cfg.progress_arc_autoscale_per_step_scale)
    1939 -    progress_arc_effective_weight = 0.0
    1940 -
    1941 -    progress_by_idx: Dict[int, float] = {}
    1942 -    ab_distance: Optional[float] = None
    1943 -    if progress_active:
    1944 -        vec_a_full = X_full_norm[pier_a]
    1945 -        vec_b_full = X_full_norm[pier_b]
    1946 -        d = vec_b_full - vec_a_full
    1947 -        denom = float(np.dot(d, d))
    1948 -        if (not math.isfinite(denom)) or denom <= 1e-12:
    1949 -            progress_active = False
    1950 -        else:
    1951 -            ab_distance = float(math.sqrt(denom))
    1952 -            progress_arc_effective_weight = float(progress_arc_weight)
    1953 -            if progress_arc_enabled and progress_arc_autoscale_enabled:
    1954 -                if ab_distance < progress_arc_autoscale_min_distance:
    1955 -                    progress_arc_effective_weight = 0.0
    1956 -                elif progress_arc_autoscale_distance_scale > 0:
    1957 -                    scale = min(1.0, ab_distance / progress_arc_autoscale_distance_scale)
    1958 -                    progress_arc_effective_weight *= float(scale)
    1959 -            if progress_arc_enabled and progress_arc_autoscale_per_step_scale:
    1960 -                progress_arc_effective_weight *= 1.0 / float(max(1, interior_length))
    1961 -
    1962 -            progress_by_idx[pier_a] = 0.0
    1963 -            progress_by_idx[pier_b] = 1.0
    1964 -            for cand in candidates:
    1965 -                i = int(cand)
    1966 -                t_raw = float(np.dot((X_full_norm[i] - vec_a_full), d) / denom)
    1967 -                t = 0.0 if not math.isfinite(t_raw) else float(max(0.0, min(1.0, t_raw)))
    1968 -                progress_by_idx[i] = t
    1969 -    if arc_stats is not None:
    1970 -        arc_stats.update(
    1971 -            {
    1972 -                "enabled": bool(progress_arc_enabled and progress_active),
    1973 -                "shape": str(progress_arc_shape),
    1974 -                "base_weight": float(progress_arc_weight),
    1975 -                "effective_weight": float(progress_arc_effective_weight),
    1976 -                "tolerance": float(progress_arc_tolerance),
    1977 -                "loss": str(progress_arc_loss),
    1978 -                "huber_delta": float(progress_arc_huber_delta),
    1979 -                "max_step": (float(progress_arc_max_step) if progress_arc_max_step is not None else None),
    1980 -                "max_step_mode": str(progress_arc_max_step_mode),
    1981 -                "max_step_penalty": float(progress_arc_max_step_penalty),
    1982 -                "autoscale": {
    1983 -                    "enabled": bool(progress_arc_autoscale_enabled),
    1984 -                    "min_distance": float(progress_arc_autoscale_min_distance),
    1985 -                    "distance_scale": float(progress_arc_autoscale_distance_scale),
    1986 -                    "per_step_scale": bool(progress_arc_autoscale_per_step_scale),
    1987 -                },
    1988 -                "ab_distance": (float(ab_distance) if ab_distance is not None else None),
    1989 -                "steps": int(interior_length),
    1990 -            }
    1991 -        )
    1992 -
    1993 -    vec_b_full = X_full_norm[pier_b]
    1994 -    sim_to_a = np.dot(X_full_norm, X_full_norm[pier_a])
    1995 -    sim_to_b = np.dot(X_full_norm, X_full_norm[pier_b])
    1996 -
    1997 -    genre_cache: Dict[tuple[int, int], float] = {}
    1998 -    genre_cache_hits = 0
    1999 -    genre_cache_misses = 0
    2000 -
    2001 -    def _get_genre_sim(a_idx: int, b_idx: int) -> Optional[float]:
    2002 -        nonlocal genre_cache_hits, genre_cache_misses
    2003 -        if X_genre_norm is None:
    2004 -            return None
    2005 -        key = (int(a_idx), int(b_idx))
    2006 -        if key in genre_cache:
    2007 -            genre_cache_hits += 1
    2008 -            return genre_cache[key]
    2009 -        genre_cache_misses += 1
    2010 -        val = float(np.dot(X_genre_norm[a_idx], X_genre_norm[b_idx]))
    2011 -        genre_cache[key] = val
    2012 -        return val
    2013 -
    2014 -    def _progress_arc_loss(cand_t: float, target_t: float) -> float:
    2015 -        err0 = abs(float(cand_t) - float(target_t))
    2016 -        err = max(0.0, err0 - progress_arc_tolerance)
    2017 -        return _progress_arc_loss_value(err, progress_arc_loss, progress_arc_huber_delta)
    2018 -
    2019 -    def _record_genre_cache_stats() -> None:
    2020 -        if genre_cache_stats is None:
    2021 -            return
    2022 -        total = int(genre_cache_hits + genre_cache_misses)
    2023 -        hit_rate = float(genre_cache_hits) / float(total) if total > 0 else None
    2024 -        genre_cache_stats.update(
    2025 -            {
    2026 -                "hits": int(genre_cache_hits),
    2027 -                "misses": int(genre_cache_misses),
    2028 -                "hit_rate": float(hit_rate) if hit_rate is not None else None,
    2029 -                "entries": int(len(genre_cache)),
    2030 -            }
    2031 -        )
    2032 -
    2033 -    # Initialize beam with pier_a
    2034 -    used_artists_init: Set[str] = set()
    2035 -
    2036 -    # Add boundary context from previous segments (cross-segment min_gap enforcement)
    2037 -    if recent_global_artists:
    2038 -        for artist_key in recent_global_artists:
    2039 -            if artist_key:
    2040 -                used_artists_init.add(str(artist_key))
    2041 -
    2042 -    if artist_key_by_idx is not None:
    2043 -        use_identity = artist_identity_cfg is not None and artist_identity_cfg.enabled
    2044 -
    2045 -        if cfg.disallow_pier_artists_in_interiors:
    2046 -            # Add pier artist keys to used_artists_init
    2047 -            for pier_idx in [pier_a, pier_b]:
    2048 -                pier_artist_str = str(artist_key_by_idx.get(int(pier_idx), "") or "")
    2049 -                if pier_artist_str:
    2050 -                    if use_identity:
    2051 -                        # Identity mode: add all identity keys for pier artist
    2052 -                        pier_identity_keys = resolve_artist_identity_keys(pier_artist_str, artist_identity_cfg)
    2053 -                        used_artists_init.update(pier_identity_keys)
    2054 -                    else:
    2055 -                        # Legacy mode: single artist key
    2056 -                        used_artists_init.add(pier_artist_str)
    2057 -
    2058 -        if cfg.disallow_seed_artist_in_interiors and seed_artist_key:
    2059 -            if use_identity:
    2060 -                # Identity mode: resolve seed artist to identity keys
    2061 -                seed_identity_keys = resolve_artist_identity_keys(seed_artist_key, artist_identity_cfg)
    2062 -                used_artists_init.update(seed_identity_keys)
    2063 -            else:
    2064 -                # Legacy mode: single seed artist key
    2065 -                used_artists_init.add(str(seed_artist_key))
    2066 -
    2067 -    initial_state = BeamState(
    2068 -        path=[pier_a],
    2069 -        score=0.0,
    2070 -        used={pier_a, pier_b},
    2071 -        used_artists=used_artists_init,
    2072 -        last_progress=0.0,
    2073 -    )
    2074 -    beam = [initial_state]
    2075 -
    2076 -    for step in range(interior_length):
    2077 -        next_beam: List[BeamState] = []
    2078 -        target_t = _step_fraction(step, interior_length)
    2079 -        experiment_target_t = (
    2080 -            _progress_target_curve(step, interior_length, progress_arc_shape)
    2081 -            if progress_arc_enabled
    2082 -            else target_t
    2083 -        )
    2084 -        g_target = g_targets[step] if waypoint_enabled and g_targets is not None else None
    2085 -
    2086 -        for state in beam:
    2087 -            current = state.path[-1]
    2088 -            apply_tie_break = (
    2089 -                (genre_tie_break_band is not None and X_genre_norm is not None and penalty_strength > 0)
    2090 -                or (waypoint_enabled and waypoint_tie_break_band is not None)
    2091 -            )
    2092 -            cand_entries: list[tuple[int, float, float, float, Optional[float], Optional[float]]] = []
    2093 -            best_score = -float("inf")
    2094 -
    2095 -            for cand in candidates:
    2096 -                if cand in state.used:
    2097 -                    continue
    2098 -
    2099 -                # Artist diversity: check if candidate artist already used
    2100 -                if artist_key_by_idx is not None:
    2101 -                    use_identity = artist_identity_cfg is not None and artist_identity_cfg.enabled
    2102 -
    2103 -                    if use_identity:
    2104 -                        # Identity mode: resolve to identity keys and check if ANY key is already used
    2105 -                        cand_artist_str = str(artist_key_by_idx.get(int(cand), "") or "")
    2106 -                        if cand_artist_str:
    2107 -                            cand_identity_keys = resolve_artist_identity_keys(cand_artist_str, artist_identity_cfg)
    2108 -                            # Reject if ANY identity key overlaps with used_artists
    2109 -                            if any(key in state.used_artists for key in cand_identity_keys):
    2110 -                                continue
    2111 -                    else:
    2112 -                        # Legacy mode: single artist key
    2113 -                        cand_artist = str(artist_key_by_idx.get(int(cand), "") or "")
    2114 -                        if cand_artist and cand_artist in state.used_artists:
    2115 -                            continue
    2116 -
    2117 -                if min(sim_to_a[cand], sim_to_b[cand]) < cfg.bridge_floor:
    2118 -                    continue
    2119 -
    2120 -                cand_t = 0.0
    2121 -                if progress_active:
    2122 -                    cand_t = float(progress_by_idx.get(int(cand), 0.0))
    2123 -                    if cand_t < float(state.last_progress) - progress_eps:
    2124 -                        continue
    2125 -                    if progress_arc_enabled and progress_arc_max_step is not None:
    2126 -                        step_jump = float(cand_t) - float(state.last_progress)
    2127 -                        if progress_arc_max_step_mode == "gate":
    2128 -                            if step_jump > float(progress_arc_max_step) + progress_eps:
    2129 -                                continue
    2130 -
    2131 -                # Compute transition score
    2132 -                trans_score = _compute_transition_score(
    2133 -                    current, cand, X_full, X_start, X_mid, X_end, cfg
    2134 -                )
    2135 -
    2136 -                # Hard floors: transition + bridge-local
    2137 -                if trans_score < cfg.transition_floor:
    2138 -                    continue
    2139 -
    2140 -                sim_a = float(sim_to_a[cand])
    2141 -                sim_b = float(sim_to_b[cand])
    2142 -                denom = sim_a + sim_b
    2143 -                bridge_score = 0.0 if denom <= 1e-9 else (2 * sim_a * sim_b) / denom
    2144 -
    2145 -                # Add heuristic pull toward destination
    2146 -                dest_pull = cfg.eta_destination_pull * float(np.dot(X_full_norm[cand], vec_b_full))
    2147 -
    2148 -                combined_score = (
    2149 -                    cfg.weight_bridge * bridge_score +
    2150 -                    cfg.weight_transition * trans_score
    2151 -                )
    2152 -                if progress_active and progress_weight > 0:
    2153 -                    combined_score -= progress_weight * abs(float(cand_t) - target_t)
    2154 -                if progress_active and progress_arc_enabled and progress_arc_effective_weight > 0:
    2155 -                    combined_score -= progress_arc_effective_weight * _progress_arc_loss(
    2156 -                        float(cand_t),
    2157 -                        experiment_target_t,
    2158 -                    )
    2159 -                if progress_active and progress_arc_enabled and progress_arc_max_step is not None:
    2160 -                    step_jump = float(cand_t) - float(state.last_progress)
    2161 -                    if step_jump > float(progress_arc_max_step):
    2162 -                        if progress_arc_max_step_mode == "penalty" and progress_arc_max_step_penalty > 0:
    2163 -                            combined_score -= progress_arc_max_step_penalty * (step_jump - float(progress_arc_max_step))
    2164 -
    2165 -                genre_sim = None
    2166 -                if X_genre_norm is not None:
    2167 -                    genre_sim = _get_genre_sim(int(current), int(cand))
    2168 -                    if genre_sim is not None and math.isfinite(genre_sim):
    2169 -                        if cfg.genre_tiebreak_weight:
    2170 -                            combined_score += cfg.genre_tiebreak_weight * genre_sim
    2171 -
    2172 -                waypoint_sim = None
    2173 -                if waypoint_enabled and g_target is not None and X_genre_norm is not None:
    2174 -                    waypoint_sim = float(np.dot(X_genre_norm[cand], g_target))
    2175 -
    2176 -                edges_scored += 1
    2177 -
    2178 -                if apply_tie_break:
    2179 -                    cand_entries.append((int(cand), float(cand_t), float(combined_score), float(dest_pull), genre_sim, waypoint_sim))
    2180 -                    if combined_score > best_score:
    2181 -                        best_score = float(combined_score)
    2182 -                else:
    2183 -                    if genre_sim is not None and math.isfinite(genre_sim):
    2184 -                        if penalty_strength > 0 and genre_sim < penalty_threshold:
    2185 -                            combined_score *= (1.0 - penalty_strength)
    2186 -                            genre_penalty_hits += 1
    2187 -                    if waypoint_enabled:
    2188 -                        combined_score += _waypoint_delta(waypoint_sim)
    2189 -                    new_score = state.score + combined_score + dest_pull
    2190 -                    new_path = state.path + [cand]
    2191 -                    new_used = state.used | {cand}
    2192 -                    new_used_artists = state.used_artists
    2193 -                    if artist_key_by_idx is not None:
    2194 -                        use_identity = artist_identity_cfg is not None and artist_identity_cfg.enabled
    2195 -                        if use_identity:
    2196 -                            # Identity mode: add ALL identity keys to used_artists
    2197 -                            cand_artist_str = str(artist_key_by_idx.get(int(cand), "") or "")
    2198 -                            if cand_artist_str:
    2199 -                                cand_identity_keys = resolve_artist_identity_keys(cand_artist_str, artist_identity_cfg)
    2200 -                                new_used_artists = state.used_artists | cand_identity_keys
    2201 -                        else:
    2202 -                            # Legacy mode: add single artist key
    2203 -                            cand_artist = str(artist_key_by_idx.get(int(cand), "") or "")
    2204 -                            if cand_artist:
    2205 -                                new_used_artists = state.used_artists | {cand_artist}
    2206 -                    new_last_progress = float(state.last_progress)
    2207 -                    if progress_active:
    2208 -                        new_last_progress = float(progress_by_idx.get(int(cand), 0.0))
    2209 -
    2210 -                    next_beam.append(BeamState(
    2211 -                        path=new_path,
    2212 -                        score=new_score,
    2213 -                        used=new_used,
    2214 -                        used_artists=new_used_artists,
    2215 -                        last_progress=new_last_progress,
    2216 -                    ))
    2217 -
    2218 -            if apply_tie_break and cand_entries:
    2219 -                for cand, cand_t, base_score, dest_pull, genre_sim, waypoint_sim in cand_entries:
    2220 -                    combined_score = float(base_score)
    2221 -                    if genre_sim is not None and math.isfinite(genre_sim):
    2222 -                        if genre_tie_break_band is not None:
    2223 -                            if (best_score - combined_score) <= float(genre_tie_break_band):
    2224 -                                if penalty_strength > 0 and genre_sim < penalty_threshold:
    2225 -                                    combined_score *= (1.0 - penalty_strength)
    2226 -                                    genre_penalty_hits += 1
    2227 -                        else:
    2228 -                            if penalty_strength > 0 and genre_sim < penalty_threshold:
    2229 -                                combined_score *= (1.0 - penalty_strength)
    2230 -                                genre_penalty_hits += 1
    2231 -                    if waypoint_enabled:
    2232 -                        if waypoint_tie_break_band is None:
    2233 -                            combined_score += _waypoint_delta(waypoint_sim)
    2234 -                        elif (best_score - combined_score) <= float(waypoint_tie_break_band):
    2235 -                            combined_score += _waypoint_delta(waypoint_sim)
    2236 -
    2237 -                    new_score = state.score + combined_score + float(dest_pull)
    2238 -                    new_path = state.path + [cand]
    2239 -                    new_used = state.used | {cand}
    2240 -                    new_used_artists = state.used_artists
    2241 -                    if artist_key_by_idx is not None:
    2242 -                        use_identity = artist_identity_cfg is not None and artist_identity_cfg.enabled
    2243 -                        if use_identity:
    2244 -                            cand_artist_str = str(artist_key_by_idx.get(int(cand), "") or "")
    2245 -                            if cand_artist_str:
    2246 -                                cand_identity_keys = resolve_artist_identity_keys(cand_artist_str, artist_identity_cfg)
    2247 -                                new_used_artists = state.used_artists | cand_identity_keys
    2248 -                        else:
    2249 -                            cand_artist = str(artist_key_by_idx.get(int(cand), "") or "")
    2250 -                            if cand_artist:
    2251 -                                new_used_artists = state.used_artists | {cand_artist}
    2252 -                    new_last_progress = float(state.last_progress)
    2253 -                    if progress_active:
    2254 -                        new_last_progress = float(progress_by_idx.get(int(cand), 0.0))
    2255 -
    2256 -                    next_beam.append(BeamState(
    2257 -                        path=new_path,
    2258 -                        score=new_score,
    2259 -                        used=new_used,
    2260 -                        used_artists=new_used_artists,
    2261 -                        last_progress=new_last_progress,
    2262 -                    ))
    2263 -
    2264 -        if not next_beam:
    2265 -            _record_genre_cache_stats()
    2266 -            return None, genre_penalty_hits, edges_scored, f"no valid continuations at step={step}"
    2267 -
    2268 -        # Keep top beam_width states
    2269 -        next_beam.sort(key=lambda s: s.score, reverse=True)
    2270 -        beam = next_beam[:beam_width]
    2271 -
    2272 -    # Final step: connect to pier_b
    2273 -    best_final: Optional[BeamState] = None
    2274 -    best_final_score = -float('inf')
    2275 -
    2276 -    for state in beam:
    2277 -        last = state.path[-1]
    2278 -        final_trans = _compute_transition_score(
    2279 -            last, pier_b, X_full, X_start, X_mid, X_end, cfg
    2280 -        )
    2281 -
    2282 -        # Hard floor on final transition
    2283 -        if final_trans < cfg.transition_floor:
    2284 -            continue
    2285 -
    2286 -        final_edge_score = final_trans
    2287 -        edges_scored += 1
    2288 -        if X_genre_norm is not None:
    2289 -            genre_sim = _get_genre_sim(int(last), int(pier_b))
    2290 -            if genre_sim is not None and math.isfinite(genre_sim):
    2291 -                if cfg.genre_tiebreak_weight:
    2292 -                    final_edge_score += cfg.genre_tiebreak_weight * genre_sim
    2293 -                if (
    2294 -                    penalty_strength > 0
    2295 -                    and genre_sim < penalty_threshold
    2296 -                ):
    2297 -                    final_edge_score *= (1.0 - penalty_strength)
    2298 -                    genre_penalty_hits += 1
    2299 -
    2300 -        total_score = state.score + final_edge_score
    2301 -        if total_score > best_final_score:
    2302 -            best_final_score = total_score
    2303 -            best_final = state
    2304 -
    2305 -    if best_final is None:
    2306 -        _record_genre_cache_stats()
    2307 -        return None, genre_penalty_hits, edges_scored, "no valid final connection to destination"
    2308 -
    2309 -    # Return interior tracks (exclude pier_a which is path[0])
    2310 -    _record_genre_cache_stats()
    2311 -    return best_final.path[1:], genre_penalty_hits, edges_scored, None
    2312 -
    2313 -
    2314 -def _compute_edge_scores(
    2315 -    path: List[int],
    2316 -    X_full: np.ndarray,
    2317 -    X_start: Optional[np.ndarray],
    2318 -    X_mid: Optional[np.ndarray],
    2319 -    X_end: Optional[np.ndarray],
    2320 -    cfg: PierBridgeConfig,
    2321 -) -> Tuple[float, float]:
    2322 -    """Compute worst and mean edge scores for a path."""
    2323 -    if len(path) < 2:
    2324 -        return (1.0, 1.0)
    2325 -
    2326 -    scores = []
    2327 -    for i in range(len(path) - 1):
    2328 -        score = _compute_transition_score(
    2329 -            path[i], path[i + 1], X_full, X_start, X_mid, X_end, cfg
    2330 -        )
    2331 -        scores.append(score)
    2332 -
    2333 -    return (min(scores), sum(scores) / len(scores))
    2334 -
    2335 -
    2336 -def _enforce_min_gap_global(
    2337 -    indices: List[int],
    2338 -    artist_keys: Optional[np.ndarray] = None,
    2339 -    min_gap: int = 1,
    2340 -    *,
    2341 -    bundle: Optional[ArtifactBundle] = None,
    2342 -    artist_identity_cfg: Optional[ArtistIdentityConfig] = None,
    2343 -) -> Tuple[List[int], int]:
    2344 -    """
    2345 -    Drop tracks that would violate a global min_gap across concatenated segments.
    2346 -
    2347 -    Pier-bridge already enforces one-per-artist per segment, but adjacent
    2348 -    duplicates can appear at segment boundaries. This pass removes any track
    2349 -    that would repeat a normalized artist within the last `min_gap` slots.
    2350 -
    2351 -    If artist_identity_cfg is provided and enabled, uses identity-based matching
    2352 -    (collapsing ensemble variants and splitting collaborations). Each collaboration
    2353 -    track contributes ALL participant identity keys to the recent window.
    2354 -    """
    2355 -    if not indices or min_gap <= 0:
    2356 -        return indices, 0
    2357 -
    2358 -    recent: List[str] = []
    2359 -    output: List[int] = []
    2360 -    dropped = 0
    2361 -
    2362 -    use_identity = artist_identity_cfg is not None and artist_identity_cfg.enabled
    2363 -
    2364 -    for idx in indices:
    2365 -        if use_identity:
    2366 -            # Identity mode: resolve artist string to identity keys (Set[str])
    2367 -            artist_str = ""
    2368 -            if bundle is not None:
    2369 -                try:
    2370 -                    artist_str = identity_keys_for_index(bundle, int(idx)).artist
    2371 -                except Exception:
    2372 -                    artist_str = ""
    2373 -            if not artist_str and artist_keys is not None:
    2374 -                try:
    2375 -                    artist_str = str(artist_keys[int(idx)])
    2376 -                except Exception:
    2377 -                    artist_str = ""
    2378 -
    2379 -            # Resolve to identity keys
    2380 -            identity_keys_set = resolve_artist_identity_keys(artist_str, artist_identity_cfg)
    2381 -
    2382 -            # Check if ANY identity key violates min_gap
    2383 -            violated_key = None
    2384 -            for identity_key in identity_keys_set:
    2385 -                if identity_key in recent:
    2386 -                    violated_key = identity_key
    2387 -                    break
    2388 -
    2389 -            if violated_key is not None:
    2390 -                dropped += 1
    2391 -                if logger.isEnabledFor(logging.DEBUG):
    2392 -                    logger.debug(
    2393 -                        "Rejected candidate idx=%d due to identity_min_gap: key=%r in recent window (distance<=%d)",
    2394 -                        idx, violated_key, min_gap
    2395 -                    )
    2396 -                continue
    2397 -
    2398 -            # Accept track: add to output and update recent window with ALL identity keys
    2399 -            output.append(idx)
    2400 -            for identity_key in identity_keys_set:
    2401 -                recent.append(identity_key)
    2402 -            # Trim recent window to size min_gap
    2403 -            while len(recent) > min_gap:
    2404 -                recent.pop(0)
    2405 -        else:
    2406 -            # Legacy mode: single artist key
    2407 -            key = ""
    2408 -            if bundle is not None:
    2409 -                try:
    2410 -                    key = identity_keys_for_index(bundle, int(idx)).artist_key
    2411 -                except Exception:
    2412 -                    key = ""
    2413 -            if not key and artist_keys is not None:
    2414 -                try:
    2415 -                    key = normalize_artist_key(str(artist_keys[int(idx)]))
    2416 -                except Exception:
    2417 -                    key = ""
    2418 -            if not key:
    2419 -                key = f"unknown_artist:{idx}"
    2420 -
    2421 -            if key in recent:
    2422 -                dropped += 1
    2423 -                continue
    2424 -
    2425 -            output.append(idx)
    2426 -            recent.append(key)
    2427 -            if len(recent) > min_gap:
    2428 -                recent.pop(0)
    2429 -
    2430 -    return output, dropped
    2431 -
    2432 -
    2433 -def build_pier_bridge_playlist(
    2434 -    *,
    2435 -    seed_track_ids: List[str],
    2436 -    total_tracks: int,
    2437 -    bundle: ArtifactBundle,
    2438 -    candidate_pool_indices: List[int],
    2439 -    cfg: Optional[PierBridgeConfig] = None,
    2440 -    min_genre_similarity: Optional[float] = None,
    2441 -    X_genre_smoothed: Optional[np.ndarray] = None,
    2442 -    genre_method: str = "ensemble",
    2443 -    internal_connector_indices: Optional[Set[int]] = None,
    2444 -    internal_connector_max_per_segment: int = 0,
    2445 -    internal_connector_priority: bool = True,
    2446 -    allowed_track_ids_set: Optional[set[str]] = None,
    2447 -    infeasible_handling: Optional[InfeasibleHandlingConfig] = None,
    2448 -    audit_config: Optional[RunAuditConfig] = None,
    2449 -    audit_events: Optional[list[RunAuditEvent]] = None,
    2450 -    artist_identity_cfg: Optional[ArtistIdentityConfig] = None,
    2451 -) -> PierBridgeResult:
    2452 -    """
    2453 -    Build playlist using pier + bridge strategy.
    2454 -
    2455 -    Args:
    2456 -        seed_track_ids: List of seed track IDs (will become piers)
    2457 -        total_tracks: Target total playlist length
    2458 -        bundle: Artifact bundle with sonic features
    2459 -        candidate_pool_indices: Pre-filtered candidate pool indices
    2460 -        cfg: Configuration (uses defaults if None)
    2461 -        min_genre_similarity: Optional genre gate threshold
    2462 -        X_genre_smoothed: Genre vectors for gating
    2463 -        genre_method: Genre similarity method
    2464 -
    2465 -    Returns:
    2466 -        PierBridgeResult with ordered track IDs and diagnostics
    2467 -    """
    2468 -    if cfg is None:
    2469 -        cfg = PierBridgeConfig()
    2470 -    if infeasible_handling is None:
    2471 -        infeasible_handling = InfeasibleHandlingConfig()
    2472 -    if audit_config is None:
    2473 -        audit_config = RunAuditConfig()
    2474 -    audit_enabled = bool(audit_config.enabled) and audit_events is not None
    2475 -    top_k = int(audit_config.include_top_k) if audit_enabled else 0
    2476 -
    2477 -    num_seeds = len(seed_track_ids)
    2478 -    if num_seeds == 0:
    2479 -        raise ValueError("At least one seed is required")
    2480 -    if num_seeds > total_tracks:
    2481 -        raise ValueError(f"Number of seeds ({num_seeds}) exceeds total_tracks ({total_tracks})")
    2482 -
    2483 -    # Resolve seed indices
    2484 -    seed_indices: List[int] = []
    2485 -    for tid in seed_track_ids:
    2486 -        idx = bundle.track_id_to_index.get(str(tid))
    2487 -        if idx is None:
    2488 -            raise ValueError(f"Seed track not found in bundle: {tid}")
    2489 -        seed_indices.append(idx)
    2490 -
    2491 -    # Remove duplicates while preserving order
    2492 -    seed_indices = list(dict.fromkeys(seed_indices))
    2493 -    num_seeds = len(seed_indices)
    2494 -    seed_id_set = {str(bundle.track_ids[i]) for i in seed_indices}
    2495 -
    2496 -    logger.info("Pier+Bridge: %d seeds, target %d tracks", num_seeds, total_tracks)
    2497 -
    2498 -    # Deduplicate candidate pool by artist+title
    2499 -    deduped_pool, _ = _dedupe_candidate_pool(candidate_pool_indices, bundle)
    2500 -
    2501 -    # Exclude seed indices from candidate pool
    2502 -    seed_set = set(seed_indices)
    2503 -    universe = [idx for idx in deduped_pool if idx not in seed_set]
    2504 -
    2505 -    logger.info("Pier+Bridge: universe size after dedupe and seed exclusion: %d", len(universe))
    2506 -
    2507 -    # Get sonic matrices (raw beat3tower space)
    2508 -    X_full_raw = bundle.X_sonic
    2509 -    X_start_raw = bundle.X_sonic_start
    2510 -    X_mid_raw = bundle.X_sonic_mid
    2511 -    X_end_raw = bundle.X_sonic_end
    2512 -
    2513 -    # Similarity space for bridge gating (full vectors) must match DS admission
    2514 -    from src.similarity.sonic_variant import compute_sonic_variant_matrix, resolve_sonic_variant
    2515 -
    2516 -    sonic_variant = resolve_sonic_variant(explicit_variant=cfg.sonic_variant, config_variant=None)
    2517 -    X_full_variant, _ = compute_sonic_variant_matrix(X_full_raw, sonic_variant, l2=False)
    2518 -    X_full_norm = _l2_normalize_rows(X_full_variant)
    2519 -    logger.debug("Pier+Bridge sonic sim space: variant=%s dim=%d", sonic_variant, int(X_full_norm.shape[1]))
    2520 -
    2521 -    # Transition space (optional tower weights + optional mean-centering)
    2522 -    from src.similarity.sonic_variant import apply_transition_weights
    2523 -
    2524 -    X_full_tr, _ = apply_transition_weights(X_full_raw, config_weights=cfg.transition_weights)
    2525 -    X_start_tr = None
    2526 -    X_mid_tr = None
    2527 -    X_end_tr = None
    2528 -    if X_start_raw is not None:
    2529 -        X_start_tr, _ = apply_transition_weights(X_start_raw, config_weights=cfg.transition_weights)
    2530 -    if X_mid_raw is not None:
    2531 -        X_mid_tr, _ = apply_transition_weights(X_mid_raw, config_weights=cfg.transition_weights)
    2532 -    if X_end_raw is not None:
    2533 -        X_end_tr, _ = apply_transition_weights(X_end_raw, config_weights=cfg.transition_weights)
    2534 -
    2535 -    if cfg.center_transitions:
    2536 -        X_full_tr = X_full_tr - X_full_tr.mean(axis=0, keepdims=True)
    2537 -        if X_start_tr is not None:
    2538 -            X_start_tr = X_start_tr - X_start_tr.mean(axis=0, keepdims=True)
    2539 -        if X_mid_tr is not None:
    2540 -            X_mid_tr = X_mid_tr - X_mid_tr.mean(axis=0, keepdims=True)
    2541 -        if X_end_tr is not None:
    2542 -            X_end_tr = X_end_tr - X_end_tr.mean(axis=0, keepdims=True)
    2543 -
    2544 -    X_full_tr_norm = _l2_normalize_rows(X_full_tr)
    2545 -    X_start_tr_norm = _l2_normalize_rows(X_start_tr) if X_start_tr is not None else None
    2546 -    X_mid_tr_norm = _l2_normalize_rows(X_mid_tr) if X_mid_tr is not None else None
    2547 -    X_end_tr_norm = _l2_normalize_rows(X_end_tr) if X_end_tr is not None else None
    2548 -
    2549 -    # Instrument transition saturation (sampled); compare raw vs transformed end→start
    2550 -    if logger.isEnabledFor(logging.DEBUG) and X_end_raw is not None and X_start_raw is not None:
    2551 -        rng = np.random.default_rng(0)
    2552 -        n = int(X_full_raw.shape[0])
    2553 -        sample_n = int(min(5000, n))
    2554 -        prev = rng.integers(0, n, size=sample_n)
    2555 -        cand = rng.integers(0, n, size=sample_n)
    2556 -        end_raw = X_end_raw[prev]
    2557 -        start_raw = X_start_raw[cand]
    2558 -        raw_sims = np.sum(end_raw * start_raw, axis=1) / (
    2559 -            (np.linalg.norm(end_raw, axis=1) * np.linalg.norm(start_raw, axis=1)) + 1e-12
    2560 -        )
    2561 -        end_tr = X_end_tr_norm[prev] if X_end_tr_norm is not None else None
    2562 -        start_tr = X_start_tr_norm[cand] if X_start_tr_norm is not None else None
    2563 -        if end_tr is not None and start_tr is not None:
    2564 -            tr_sims = np.sum(end_tr * start_tr, axis=1)
    2565 -            if cfg.center_transitions:
    2566 -                tr_sims = (tr_sims + 1.0) / 2.0
    2567 -            logger.debug(
    2568 -                "Transition end→start sample: raw[min=%.4f p05=%.4f p50=%.4f p95=%.4f max=%.4f] "
    2569 -                "transformed[min=%.4f p05=%.4f p50=%.4f p95=%.4f max=%.4f] center_transitions=%s",
    2570 -                float(np.min(raw_sims)),
    2571 -                float(np.percentile(raw_sims, 5)),
    2572 -                float(np.percentile(raw_sims, 50)),
    2573 -                float(np.percentile(raw_sims, 95)),
    2574 -                float(np.max(raw_sims)),
    2575 -                float(np.min(tr_sims)),
    2576 -                float(np.percentile(tr_sims, 5)),
    2577 -                float(np.percentile(tr_sims, 50)),
    2578 -                float(np.percentile(tr_sims, 95)),
    2579 -                float(np.max(tr_sims)),
    2580 -                bool(cfg.center_transitions),
    2581 -            )
    2582 -
    2583 -    # For seed ordering bridgeability heuristic, prefer transition-normalized mats when present
    2584 -    X_start_norm = X_start_tr_norm
    2585 -    X_end_norm = X_end_tr_norm
    2586 -
    2587 -    # Genre similarity for soft edge penalty / tiebreak (cosine on smoothed genre vectors)
    2588 -    X_genre_use = X_genre_smoothed if X_genre_smoothed is not None else getattr(bundle, "X_genre_smoothed", None)
    2589 -    X_genre_norm = None
    2590 -    if X_genre_use is not None:
    2591 -        denom_g = np.linalg.norm(X_genre_use, axis=1, keepdims=True) + 1e-12
    2592 -        X_genre_norm = X_genre_use / denom_g
    2593 -
    2594 -    warnings: list[dict[str, Any]] = []
    2595 -    if bool(cfg.dj_bridging_enabled):
    2596 -        if X_genre_norm is None:
    2597 -            warnings.append({
    2598 -                "type": "genre_missing",
    2599 -                "scope": "global",
    2600 -                "message": "Genre guidance reduced because metadata is missing; consider adding genres.",
    2601 -                "anchors_missing": int(num_seeds),
    2602 -            })
    2603 -        else:
    2604 -            seed_vecs = X_genre_norm[seed_indices]
    2605 -            norms = np.linalg.norm(seed_vecs, axis=1)
    2606 -            missing_ids = [
    2607 -                str(bundle.track_ids[idx])
    2608 -                for idx, nval in zip(seed_indices, norms)
    2609 -                if float(nval) <= 1e-8
    2610 -            ]
    2611 -            if missing_ids:
    2612 -                warnings.append({
    2613 -                    "type": "genre_missing",
    2614 -                    "scope": "anchors",
    2615 -                    "message": "Genre guidance reduced because metadata is missing; consider adding genres.",
    2616 -                    "missing_anchor_ids": missing_ids,
    2617 -                })
    2618 -        if bool(cfg.dj_anchors_must_include_all) and len(seed_indices) != len(seed_track_ids):
    2619 -            warnings.append({
    2620 -                "type": "anchor_deduped",
    2621 -                "scope": "anchors",
    2622 -                "message": "Duplicate anchors were removed while must_include_all is set.",
    2623 -                "requested_count": int(len(seed_track_ids)),
    2624 -                "resolved_count": int(len(seed_indices)),
    2625 -            })
    2626 -
    2627 -    genre_graph: Optional[dict[str, list[tuple[str, float]]]] = None
    2628 -    if bool(cfg.dj_bridging_enabled):
    2629 -        route_shape = str(cfg.dj_route_shape or "linear").strip().lower()
    2630 -        if route_shape == "ladder":
    2631 -            genre_vocab = getattr(bundle, "genre_vocab", None)
    2632 -            if genre_vocab is None:
    2633 -                warnings.append({
    2634 -                    "type": "genre_ladder_unavailable",
    2635 -                    "scope": "global",
    2636 -                    "message": "Genre ladder disabled; missing genre vocab.",
    2637 -                })
    2638 -            else:
    2639 -                repo_root = Path(__file__).resolve().parents[2]
    2640 -                genre_yaml = repo_root / "data" / "genre_similarity.yaml"
    2641 -                genre_graph = _load_genre_similarity_graph(
    2642 -                    genre_yaml,
    2643 -                    min_similarity=float(cfg.dj_ladder_min_similarity),
    2644 -                )
    2645 -                if not genre_graph:
    2646 -                    warnings.append({
    2647 -                        "type": "genre_ladder_unavailable",
    2648 -                        "scope": "global",
    2649 -                        "message": "Genre ladder disabled; similarity graph unavailable.",
    2650 -                    })
    2651 -
    2652 -    # Precompute allowed indices set if caller passed allowed_track_ids_set.
    2653 -    # (In style-aware runs, the bundle is often already restricted, but this still
    2654 -    # acts as a hard gate for candidate admission inside pier-bridge.)
    2655 -    allowed_set_indices: Optional[Set[int]] = None
    2656 -    if allowed_track_ids_set is not None:
    2657 -        allowed_set_indices = set()
    2658 -        for tid in allowed_track_ids_set:
    2659 -            idx = bundle.track_id_to_index.get(str(tid))
    2660 -            if idx is not None:
    2661 -                allowed_set_indices.add(idx)
    2662 -        # Ensure piers are always allowed
    2663 -        allowed_set_indices.update(seed_indices)
    2664 -
    2665 -    # Order seeds by bridgeability (or preserve order if fixed)
    2666 -    seed_ordering = str(cfg.dj_seed_ordering or "auto").strip().lower()
    2667 -    if seed_ordering not in {"auto", "fixed"}:
    2668 -        warnings.append({
    2669 -            "type": "seed_ordering_invalid",
    2670 -            "scope": "anchors",
    2671 -            "message": f"Unknown seed_ordering '{seed_ordering}', defaulting to auto.",
    2672 -        })
    2673 -        seed_ordering = "auto"
    2674 -    if bool(cfg.dj_bridging_enabled) and seed_ordering == "fixed":
    2675 -        ordered_seeds = list(seed_indices)
    2676 -    else:
    2677 -        if bool(cfg.dj_bridging_enabled):
    2678 -            ordered_seeds = _order_seeds_by_bridgeability(
    2679 -                seed_indices,
    2680 -                X_full_norm,
    2681 -                X_start_norm,
    2682 -                X_end_norm,
    2683 -                X_genre_norm,
    2684 -                weight_sonic=float(cfg.dj_seed_ordering_weight_sonic),
    2685 -                weight_genre=float(cfg.dj_seed_ordering_weight_genre),
    2686 -                weight_bridge=float(cfg.dj_seed_ordering_weight_bridge),
    2687 -            )
    2688 -        else:
    2689 -            ordered_seeds = _order_seeds_by_bridgeability(
    2690 -                seed_indices, X_full_norm, X_start_norm, X_end_norm
    2691 -            )
    2692 -
    2693 -    logger.info("Pier+Bridge: seed order = %s",
    2694 -               [str(bundle.track_ids[i]) for i in ordered_seeds])
    2695 -
    2696 -    # Handle single seed as both start AND end pier (arc structure)
    2697 -    # This creates a playlist that starts from seed, explores, and returns to seed-similar sounds
    2698 -    is_single_seed_arc = (num_seeds == 1)
    2699 -    if is_single_seed_arc:
    2700 -        # Duplicate the seed as both start and end pier
    2701 -        ordered_seeds = [ordered_seeds[0], ordered_seeds[0]]
    2702 -        num_segments = 1
    2703 -        total_interior = total_tracks - 1  # Only one seed in final output
    2704 -        logger.info("Pier+Bridge: single-seed arc mode (seed is both start and end pier)")
    2705 -    else:
    2706 -        num_segments = num_seeds - 1
    2707 -        total_interior = total_tracks - num_seeds
    2708 -
    2709 -    # Even split with remainder distributed to earlier segments
    2710 -    base_length = total_interior // num_segments
    2711 -    remainder = total_interior % num_segments
    2712 -    segment_lengths = [
    2713 -        base_length + (1 if i < remainder else 0)
    2714 -        for i in range(num_segments)
    2715 -    ]
    2716 -
    2717 -    logger.info("Pier+Bridge: segment lengths = %s (total_interior=%d)",
    2718 -               segment_lengths, total_interior)
    2719 -
    2720 -    # Build segments
    2721 -    global_used: Set[int] = set(ordered_seeds)  # Seeds are already "used"
    2722 -    # Track-key dedupe across the full run: prevent "same song twice" even if track_id differs.
    2723 -    seed_artist_key: Optional[str] = None
    2724 -    try:
    2725 -        if seed_indices:
    2726 -            seed_artist_key = identity_keys_for_index(bundle, int(seed_indices[0])).artist_key
    2727 -    except Exception:
    2728 -        seed_artist_key = None
    2729 -
    2730 -    seed_track_keys: Set[tuple[str, str]] = set()
    2731 -    for sidx in set(int(i) for i in seed_indices):
    2732 -        try:
    2733 -            seed_track_keys.add(identity_keys_for_index(bundle, int(sidx)).track_key)
    2734 -        except Exception:
    2735 -            continue
    2736 -    used_track_keys: Set[tuple[str, str]] = set(seed_track_keys)
    2737 -
    2738 -    all_segments: List[List[int]] = []
    2739 -    diagnostics: List[SegmentDiagnostics] = []
    2740 -    soft_genre_penalty_hits_total = 0
    2741 -    soft_genre_penalty_edges_scored_total = 0
    2742 -    segment_bridge_floors_used: list[float] = []
    2743 -    segment_backoff_attempts_used: list[int] = []
    2744 -
    2745 -    # Boundary context tracking for cross-segment min_gap enforcement
    2746 -    # Tracks artist keys from the last min_gap positions of the concatenated result
    2747 -    MIN_GAP_GLOBAL = 1  # Cross-segment min_gap constraint
    2748 -    recent_boundary_artists: List[str] = []
    2749 -
    2750 -    def _bridge_floor_attempts(initial_floor: float) -> list[float]:
    2751 -        if not infeasible_handling or not infeasible_handling.enabled:
    2752 -            return [float(initial_floor)]
    2753 -        steps = list(infeasible_handling.backoff_steps or ())
    2754 -        if not steps:
    2755 -            cur = float(initial_floor)
    2756 -            while cur >= float(infeasible_handling.min_bridge_floor) - 1e-9:
    2757 -                steps.append(round(cur, 2))
    2758 -                cur -= 0.01
    2759 -        attempts: list[float] = [float(initial_floor)]
    2760 -        for v in steps:
    2761 -            if not isinstance(v, (int, float)):
    2762 -                continue
    2763 -            f = float(v)
    2764 -            if f < float(initial_floor) and f >= float(infeasible_handling.min_bridge_floor) - 1e-9:
    2765 -                attempts.append(float(f))
    2766 -        attempts = list(dict.fromkeys(attempts))
    2767 -        max_attempts = max(1, int(infeasible_handling.max_attempts_per_segment))
    2768 -        return attempts[:max_attempts]
    2769 -
    2770 -    for seg_idx in range(num_segments):
    2771 -        pier_a = ordered_seeds[seg_idx]
    2772 -        pier_b = ordered_seeds[seg_idx + 1]
    2773 -        interior_len = segment_lengths[seg_idx]
    2774 -
    2775 -        pier_a_id = str(bundle.track_ids[pier_a])
    2776 -        pier_b_id = str(bundle.track_ids[pier_b])
    2777 -
    2778 -        logger.info("Building segment %d: %s -> %s (interior=%d)",
    2779 -                   seg_idx, pier_a_id, pier_b_id, interior_len)
    2780 -
    2781 -        segment_g_targets: Optional[list[np.ndarray]] = None
    2782 -        segment_far_stats: Optional[dict[str, Optional[float]]] = None
    2783 -        segment_is_far = False
    2784 -        if bool(cfg.dj_bridging_enabled) and X_genre_norm is not None:
    2785 -            genre_vocab = getattr(bundle, "genre_vocab", None)
    2786 -            if genre_vocab is not None:
    2787 -                segment_g_targets = _build_genre_targets(
    2788 -                    pier_a=pier_a,
    2789 -                    pier_b=pier_b,
    2790 -                    interior_length=interior_len,
    2791 -                    X_full_norm=X_full_norm,
    2792 -                    X_genre_norm=X_genre_norm,
    2793 -                    genre_vocab=genre_vocab,
    2794 -                    genre_graph=genre_graph,
    2795 -                    cfg=cfg,
    2796 -                    warnings=warnings,
    2797 -                )
    2798 -            segment_far_stats = _segment_far_stats(
    2799 -                pier_a=pier_a,
    2800 -                pier_b=pier_b,
    2801 -                X_full_norm=X_full_norm,
    2802 -                X_genre_norm=X_genre_norm,
    2803 -                universe=universe,
    2804 -                used_track_ids=global_used,
    2805 -                bridge_floor=float(cfg.bridge_floor),
    2806 -            )
    2807 -            if segment_far_stats:
    2808 -                sonic_sim = segment_far_stats.get("sonic_sim")
    2809 -                genre_sim = segment_far_stats.get("genre_sim")
    2810 -                scarcity = segment_far_stats.get("connector_scarcity")
    2811 -                if sonic_sim is not None and (1.0 - float(sonic_sim)) > float(cfg.dj_far_threshold_sonic):
    2812 -                    segment_is_far = True
    2813 -                if genre_sim is not None and (1.0 - float(genre_sim)) > float(cfg.dj_far_threshold_genre):
    2814 -                    segment_is_far = True
    2815 -                if scarcity is not None and float(scarcity) < float(cfg.dj_far_threshold_connector_scarcity):
    2816 -                    segment_is_far = True
    2817 -        segment_allow_detours = bool(cfg.dj_allow_detours_when_far) and segment_is_far
    2818 -
    2819 -        # Optional bridge_floor backoff on infeasible segments (default OFF)
    2820 -        segment_path: Optional[List[int]] = None
    2821 -        chosen_bridge_floor = float(cfg.bridge_floor)
    2822 -        backoff_attempts = _bridge_floor_attempts(float(cfg.bridge_floor))
    2823 -        backoff_used_count = 0
    2824 -        widened_search_used = False
    2825 -        last_failure_reason: Optional[str] = None
    2826 -
    2827 -        # Defaults for diagnostics (filled on success/last attempt)
    2828 -        expansions = 0
    2829 -        pool_size_initial = 0
    2830 -        pool_size_final = 0
    2831 -        beam_width_used = cfg.initial_beam_width
    2832 -        soft_genre_penalty_hits_segment = 0
    2833 -        soft_genre_penalty_edges_scored_segment = 0
    2834 -
    2835 -        for floor_attempt_idx, bridge_floor in enumerate(backoff_attempts):
    2836 -            backoff_used_count = floor_attempt_idx + 1
    2837 -            widened = bool(
    2838 -                infeasible_handling
    2839 -                and infeasible_handling.enabled
    2840 -                and infeasible_handling.widen_search_on_backoff
    2841 -                and floor_attempt_idx > 0
    2842 -            )
    2843 -            widened_search_used = widened_search_used or widened
    2844 -            cfg_attempt = replace(cfg, bridge_floor=float(bridge_floor))
    2845 -
    2846 -            segment_pool_max = int(cfg.segment_pool_max)
    2847 -            beam_width = cfg.initial_beam_width
    2848 -            max_expansion_attempts = cfg.max_expansion_attempts
    2849 -            if widened:
    2850 -                extra_pool = int(infeasible_handling.extra_neighbors_m) + int(infeasible_handling.extra_bridge_helpers)
    2851 -                segment_pool_max = min(segment_pool_max + extra_pool, int(cfg.max_segment_pool_max))
    2852 -                beam_width = min(beam_width + int(infeasible_handling.extra_beam_width), cfg.max_beam_width)
    2853 -                max_expansion_attempts = max_expansion_attempts + int(infeasible_handling.extra_expansion_attempts)
    2854 -
    2855 -            expansions = 0
    2856 -            pool_size_initial = 0
    2857 -            pool_size_final = 0
    2858 -            soft_genre_penalty_hits_segment = 0
    2859 -            soft_genre_penalty_edges_scored_segment = 0
    2860 -            last_failure_reason = None
    2861 -            expansion_attempts_used = 0
    2862 -            last_pool_diag: Dict[str, Any] = {}
    2863 -            last_segment_candidates: List[int] = []
    2864 -            last_candidate_artist_keys: Dict[int, str] = {}
    2865 -            last_arc_stats: Dict[str, Any] = {}
    2866 -            last_genre_cache_stats: Dict[str, int] = {}
    2867 -            segment_pool_cache: Optional[Dict[str, Any]] = (
    2868 -                {} if bool(cfg.dj_pooling_cache_enabled) else None
    2869 -            )
    2870 -            last_segment_pool_max = int(segment_pool_max)
    2871 -            last_beam_width = int(beam_width)
    2872 -
    2873 -            for attempt in range(max_expansion_attempts):
    2874 -                pool_diag: Dict[str, Any] = {}
    2875 -                cand_artist_keys: Dict[int, str] = {}
    2876 -                arc_stats_segment: Dict[str, Any] = {}
    2877 -                genre_cache_stats_segment: Dict[str, int] = {}
    2878 -                pool_strategy = str(cfg.segment_pool_strategy).strip().lower()
    2879 -                dj_pooling_strategy = str(cfg.dj_pooling_strategy or "baseline").strip().lower()
    2880 -                if bool(cfg.dj_bridging_enabled) and dj_pooling_strategy == "dj_union":
    2881 -                    pool_strategy = "dj_union"
    2882 -
    2883 -                segment_internal_connectors = internal_connector_indices
    2884 -                segment_connector_cap = int(internal_connector_max_per_segment)
    2885 -                if bool(cfg.dj_bridging_enabled) and bool(cfg.dj_connector_bias_enabled) and segment_allow_detours:
    2886 -                    adventurous = str(cfg.dj_route_shape or "linear").strip().lower() in {"arc", "ladder"}
    2887 -                    dj_connector_cap = (
    2888 -                        int(cfg.dj_connector_max_per_segment_adventurous)
    2889 -                        if adventurous
    2890 -                        else int(cfg.dj_connector_max_per_segment_linear)
    2891 -                    )
    2892 -                    dj_connector_cap = max(0, dj_connector_cap)
    2893 -                    if dj_connector_cap > 0:
    2894 -                        available = [int(i) for i in universe if int(i) not in global_used]
    2895 -                        if allowed_set_indices is not None:
    2896 -                            allowed = set(int(i) for i in allowed_set_indices)
    2897 -                            available = [int(i) for i in available if int(i) in allowed]
    2898 -                        if available:
    2899 -                            vec_a = X_full_norm[pier_a]
    2900 -                            vec_b = X_full_norm[pier_b]
    2901 -                            sims_a = np.dot(X_full_norm[available], vec_a)
    2902 -                            sims_b = np.dot(X_full_norm[available], vec_b)
    2903 -                            scores = np.minimum(sims_a, sims_b)
    2904 -                            order = np.argsort(-scores)
    2905 -                            dj_connectors = [available[int(i)] for i in order[:dj_connector_cap]]
    2906 -                        else:
    2907 -                            dj_connectors = []
    2908 -                        pool_diag["dj_connectors_selected"] = int(len(dj_connectors))
    2909 -                        if dj_connectors:
    2910 -                            if segment_internal_connectors:
    2911 -                                segment_internal_connectors = set(segment_internal_connectors) | set(dj_connectors)
    2912 -                            else:
    2913 -                                segment_internal_connectors = set(dj_connectors)
    2914 -                            segment_connector_cap = max(segment_connector_cap, dj_connector_cap)
    2915 -                if pool_strategy == "legacy":
    2916 -                    # Legacy/compat strategy (combined neighbor pooling).
    2917 -                    neighbors_m = min(int(cfg.initial_neighbors_m) * (2 ** int(attempt)), int(cfg.max_neighbors_m))
    2918 -                    bridge_helpers = min(int(cfg.initial_bridge_helpers) * (2 ** int(attempt)), int(cfg.max_bridge_helpers))
    2919 -                    pool_diag["pool_strategy"] = "legacy"
    2920 -                    pool_diag["neighbors_m"] = int(neighbors_m)
    2921 -                    pool_diag["bridge_helpers"] = int(bridge_helpers)
    2922 -                    segment_candidates = _build_segment_candidate_pool_legacy(
    2923 -                        pier_a,
    2924 -                        pier_b,
    2925 -                        X_full_norm,
    2926 -                        universe,
    2927 -                        global_used,
    2928 -                        int(neighbors_m),
    2929 -                        int(bridge_helpers),
    2930 -                        artist_keys=bundle.artist_keys,
    2931 -                        bridge_floor=float(bridge_floor),
    2932 -                        allowed_set=(allowed_set_indices if allowed_set_indices is not None else None),
    2933 -                        internal_connectors=segment_internal_connectors,
    2934 -                        internal_connector_cap=segment_connector_cap,
    2935 -                        internal_connector_priority=internal_connector_priority,
    2936 -                        diagnostics=pool_diag,
    2937 -                    )
    2938 -                    try:
    2939 -                        cand_artist_keys[int(pier_a)] = identity_keys_for_index(bundle, int(pier_a)).artist_key
    2940 -                        cand_artist_keys[int(pier_b)] = identity_keys_for_index(bundle, int(pier_b)).artist_key
    2941 -                        for c in segment_candidates:
    2942 -                            cand_artist_keys[int(c)] = identity_keys_for_index(bundle, int(c)).artist_key
    2943 -                    except Exception:
    2944 -                        cand_artist_keys = {}
    2945 -                else:
    2946 -                    pool_diag["pool_strategy"] = pool_strategy
    2947 -                    segment_candidates, cand_artist_keys, _cand_title_keys = _build_segment_candidate_pool_scored(
    2948 -                        pier_a=pier_a,
    2949 -                        pier_b=pier_b,
    2950 -                        X_full_norm=X_full_norm,
    2951 -                        universe_indices=universe,
    2952 -                        used_track_ids=global_used,
    2953 -                        bundle=bundle,
    2954 -                        bridge_floor=float(bridge_floor),
    2955 -                        segment_pool_max=int(segment_pool_max),
    2956 -                        allowed_set=allowed_set_indices if allowed_set_indices is not None else None,
    2957 -                        internal_connectors=segment_internal_connectors,
    2958 -                        internal_connector_cap=segment_connector_cap,
    2959 -                        internal_connector_priority=internal_connector_priority,
    2960 -                        seed_artist_key=seed_artist_key,
    2961 -                        disallow_pier_artists_in_interiors=bool(cfg.disallow_pier_artists_in_interiors),
    2962 -                        disallow_seed_artist_in_interiors=bool(cfg.disallow_seed_artist_in_interiors),
    2963 -                        used_track_keys=used_track_keys,
    2964 -                        seed_track_keys=seed_track_keys,
    2965 -                        diagnostics=pool_diag,
    2966 -                        experiment_bridge_scoring_enabled=bool(
    2967 -                            cfg.experiment_bridge_scoring_enabled
    2968 -                        ),
    2969 -                        experiment_bridge_min_weight=float(
    2970 -                            cfg.experiment_bridge_min_weight
    2971 -                        ),
    2972 -                        experiment_bridge_balance_weight=float(
    2973 -                            cfg.experiment_bridge_balance_weight
    2974 -                        ),
    2975 -                        pool_strategy=str(pool_strategy),
    2976 -                        interior_length=int(interior_len),
    2977 -                        progress_arc_enabled=bool(cfg.progress_arc_enabled),
    2978 -                        progress_arc_shape=str(cfg.progress_arc_shape),
    2979 -                        X_genre_norm=X_genre_norm,
    2980 -                        genre_targets=segment_g_targets,
    2981 -                        pool_k_local=int(cfg.dj_pooling_k_local),
    2982 -                        pool_k_toward=int(cfg.dj_pooling_k_toward),
    2983 -                        pool_k_genre=int(cfg.dj_pooling_k_genre),
    2984 -                        pool_k_union_max=int(cfg.dj_pooling_k_union_max),
    2985 -                        pool_step_stride=int(cfg.dj_pooling_step_stride),
    2986 -                        pool_cache_enabled=bool(cfg.dj_pooling_cache_enabled),
    2987 -                        pooling_cache=segment_pool_cache,
    2988 -                    )
    2989 -                    try:
    2990 -                        cand_artist_keys = dict(cand_artist_keys)
    2991 -                        cand_artist_keys[int(pier_a)] = identity_keys_for_index(bundle, int(pier_a)).artist_key
    2992 -                        cand_artist_keys[int(pier_b)] = identity_keys_for_index(bundle, int(pier_b)).artist_key
    2993 -                    except Exception:
    2994 -                        cand_artist_keys = {}
    2995 -                expansion_attempts_used = attempt + 1
    2996 -                if attempt == 0:
    2997 -                    pool_size_initial = len(segment_candidates)
    2998 -                pool_size_final = len(segment_candidates)
    2999 -                last_pool_diag = dict(pool_diag)
    3000 -                last_segment_candidates = list(segment_candidates)
    3001 -                last_candidate_artist_keys = dict(cand_artist_keys)
    3002 -                last_arc_stats = dict(arc_stats_segment)
    3003 -                last_genre_cache_stats = dict(genre_cache_stats_segment)
    3004 -                last_segment_pool_max = int(segment_pool_max)
    3005 -                last_beam_width = int(beam_width)
    3006 -
    3007 -                if len(segment_candidates) < interior_len:
    3008 -                    last_failure_reason = f"pool_after_gate {len(segment_candidates)} < interior_len {interior_len}"
    3009 -                    segment_path = None
    3010 -                    soft_genre_penalty_hits_segment = 0
    3011 -                    soft_genre_penalty_edges_scored_segment = 0
    3012 -                    beam_failure_reason = None
    3013 -                else:
    3014 -                    if cand_artist_keys:
    3015 -                        try:
    3016 -                            cand_artist_keys[int(pier_a)] = identity_keys_for_index(
    3017 -                                bundle, int(pier_a)
    3018 -                            ).artist_key
    3019 -                            cand_artist_keys[int(pier_b)] = identity_keys_for_index(
    3020 -                                bundle, int(pier_b)
    3021 -                            ).artist_key
    3022 -                        except Exception:
    3023 -                            pass
    3024 -                    segment_path, soft_genre_penalty_hits_segment, soft_genre_penalty_edges_scored_segment, beam_failure_reason = _beam_search_segment(
    3025 -                        pier_a,
    3026 -                        pier_b,
    3027 -                        interior_len,
    3028 -                        segment_candidates,
    3029 -                        X_full_tr_norm,
    3030 -                        X_full_norm,
    3031 -                        X_start_tr_norm,
    3032 -                        X_mid_tr_norm,
    3033 -                        X_end_tr_norm,
    3034 -                        X_genre_norm,
    3035 -                        cfg_attempt,
    3036 -                        beam_width,
    3037 -                        artist_key_by_idx=(cand_artist_keys if cand_artist_keys else None),
    3038 -                        seed_artist_key=seed_artist_key,
    3039 -                        recent_global_artists=recent_boundary_artists if seg_idx > 0 else None,
    3040 -                        durations_ms=bundle.durations_ms,
    3041 -                        artist_identity_cfg=artist_identity_cfg,
    3042 -                        bundle=bundle,
    3043 -                        arc_stats=arc_stats_segment,
    3044 -                        genre_cache_stats=genre_cache_stats_segment,
    3045 -                        g_targets_override=segment_g_targets,
    3046 -                    )
    3047 -                    last_failure_reason = beam_failure_reason
    3048 -
    3049 -                if segment_path is not None:
    3050 -                    break
    3051 -
    3052 -                expansions += 1
    3053 -                if str(cfg.segment_pool_strategy).strip().lower() != "legacy":
    3054 -                    segment_pool_max = min(int(segment_pool_max) * 2, int(cfg.max_segment_pool_max))
    3055 -                beam_width = min(int(beam_width) * 2, int(cfg.max_beam_width))
    3056 -
    3057 -                if infeasible_handling and infeasible_handling.enabled:
    3058 -                    if str(cfg.segment_pool_strategy).strip().lower() == "legacy":
    3059 -                        logger.debug(
    3060 -                            "Segment %d: expanding search (expansion_attempt=%d strategy=legacy beam=%d)",
    3061 -                            seg_idx,
    3062 -                            attempt + 1,
    3063 -                            beam_width,
    3064 -                        )
    3065 -                    else:
    3066 -                        logger.debug(
    3067 -                            "Segment %d: expanding search (expansion_attempt=%d segment_pool_max=%d beam=%d)",
    3068 -                            seg_idx,
    3069 -                            attempt + 1,
    3070 -                            int(segment_pool_max),
    3071 -                            beam_width,
    3072 -                        )
    3073 -
    3074 -            if infeasible_handling and infeasible_handling.enabled:
    3075 -                logger.info(
    3076 -                    "Segment %d attempt %d: bridge_floor=%.2f widened=%s pool_after_gate=%d",
    3077 -                    seg_idx,
    3078 -                    floor_attempt_idx + 1,
    3079 -                    float(bridge_floor),
    3080 -                    widened,
    3081 -                    int(len(last_segment_candidates)),
    3082 -                )
    3083 -
    3084 -            if audit_enabled:
    3085 -                top_rows, dists = _summarize_candidates_for_audit(
    3086 -                    candidates=last_segment_candidates,
    3087 -                    pier_a=pier_a,
    3088 -                    pier_b=pier_b,
    3089 -                    X_full_norm=X_full_norm,
    3090 -                    X_full_tr_norm=X_full_tr_norm,
    3091 -                    X_start_tr_norm=X_start_tr_norm,
    3092 -                    X_mid_tr_norm=X_mid_tr_norm,
    3093 -                    X_end_tr_norm=X_end_tr_norm,
    3094 -                    X_genre_norm=X_genre_norm,
    3095 -                    cfg=cfg_attempt,
    3096 -                    bundle=bundle,
    3097 -                    internal_connector_indices=internal_connector_indices,
    3098 -                    top_k=top_k,
    3099 -                )
    3100 -                audit_events.append(
    3101 -                    RunAuditEvent(
    3102 -                        kind="segment_attempt",
    3103 -                        ts_utc=now_utc_iso(),
    3104 -                        payload={
    3105 -                            "segment_index": int(seg_idx),
    3106 -                            "segment_header": f"{pier_a_id} -> {pier_b_id} (interior={interior_len})",
    3107 -                            "attempt_number": int(floor_attempt_idx + 1),
    3108 -                            "expansion_attempts": int(expansion_attempts_used),
    3109 -                            "bridge_floor": float(bridge_floor),
    3110 -                            "widened": bool(widened),
    3111 -                            "segment_pool_strategy": str(
    3112 -                                last_pool_diag.get("pool_strategy", cfg.segment_pool_strategy)
    3113 -                            ),
    3114 -                            "segment_pool_max": int(last_segment_pool_max),
    3115 -                            "beam_width": int(last_beam_width),
    3116 -                            "pool_counts": dict(last_pool_diag),
    3117 -                            "pool_size_initial": int(pool_size_initial),
    3118 -                            "pool_size_final": int(pool_size_final),
    3119 -                            "distributions": dists,
    3120 -                            "soft_genre_penalty": {
    3121 -                                "edges_scored": int(soft_genre_penalty_edges_scored_segment),
    3122 -                                "hits": int(soft_genre_penalty_hits_segment),
    3123 -                                "threshold": float(cfg_attempt.genre_penalty_threshold),
    3124 -                                "strength": float(cfg_attempt.genre_penalty_strength),
    3125 -                            },
    3126 -                            "genre_cache": dict(last_genre_cache_stats),
    3127 -                            "progress_arc": dict(last_arc_stats),
    3128 -                            "top_candidates": top_rows,
    3129 -                            "reason": ("success" if segment_path is not None else last_failure_reason),
    3130 -                        },
    3131 -                    )
    3132 -                )
    3133 -
    3134 -            if segment_path is not None:
    3135 -                chosen_bridge_floor = float(bridge_floor)
    3136 -                beam_width_used = int(last_beam_width)
    3137 -                if audit_enabled:
    3138 -                    arc_tracking = _compute_progress_tracking_metrics(
    3139 -                        path=segment_path,
    3140 -                        pier_a=pier_a,
    3141 -                        pier_b=pier_b,
    3142 -                        X_full_norm=X_full_norm,
    3143 -                        shape=str(cfg_attempt.progress_arc_shape),
    3144 -                    )
    3145 -                    audit_events.append(
    3146 -                        RunAuditEvent(
    3147 -                            kind="segment_success",
    3148 -                            ts_utc=now_utc_iso(),
    3149 -                            payload={
    3150 -                                "segment_index": int(seg_idx),
    3151 -                                "bridge_floor_used": float(chosen_bridge_floor),
    3152 -                                "backoff_attempts_used": int(backoff_used_count),
    3153 -                                "widened_search": bool(widened_search_used),
    3154 -                                "progress_arc_tracking": arc_tracking,
    3155 -                            },
    3156 -                        )
    3157 -                    )
    3158 -                break
    3159 -
    3160 -        if segment_path is None:
    3161 -            if bool(cfg.dj_bridging_enabled) and bool(cfg.dj_micro_piers_enabled) and segment_allow_detours:
    3162 -                micro_path = _attempt_micro_pier_split(
    3163 -                    pier_a=pier_a,
    3164 -                    pier_b=pier_b,
    3165 -                    interior_length=interior_len,
    3166 -                    candidates=last_segment_candidates,
    3167 -                    X_full=X_full_tr_norm,
    3168 -                    X_full_norm=X_full_norm,
    3169 -                    X_start=X_start_tr_norm,
    3170 -                    X_mid=X_mid_tr_norm,
    3171 -                    X_end=X_end_tr_norm,
    3172 -                    X_genre_norm=X_genre_norm,
    3173 -                    cfg=cfg_attempt,
    3174 -                    beam_width=beam_width,
    3175 -                    artist_key_by_idx=last_candidate_artist_keys,
    3176 -                    seed_artist_key=seed_artist_key,
    3177 -                    recent_global_artists=recent_boundary_artists if seg_idx > 0 else None,
    3178 -                    durations_ms=bundle.durations_ms,
    3179 -                    artist_identity_cfg=artist_identity_cfg,
    3180 -                    bundle=bundle,
    3181 -                    warnings=warnings,
    3182 -                    X_genre_vocab=getattr(bundle, "genre_vocab", None),
    3183 -                    genre_graph=genre_graph,
    3184 -                )
    3185 -                if micro_path is not None and len(micro_path) == interior_len:
    3186 -                    segment_path = micro_path
    3187 -
    3188 -            if audit_enabled:
    3189 -                audit_events.append(
    3190 -                    RunAuditEvent(
    3191 -                        kind="segment_failure",
    3192 -                        ts_utc=now_utc_iso(),
    3193 -                        payload={
    3194 -                            "segment_index": int(seg_idx),
    3195 -                            "failure_reason": str(last_failure_reason or "segment infeasible"),
    3196 -                            "attempted_bridge_floors": [float(x) for x in backoff_attempts],
    3197 -                        },
    3198 -                    )
    3199 -                )
    3200 -            if infeasible_handling and infeasible_handling.enabled:
    3201 -                failure = f"Segment {seg_idx} infeasible under bridge_floor backoff (attempted={backoff_attempts}; last_reason={last_failure_reason})"
    3202 -            else:
    3203 -                failure = f"Segment {seg_idx} infeasible under bridge_floor={cfg.bridge_floor}"
    3204 -            logger.error(failure)
    3205 -            return PierBridgeResult(
    3206 -                track_ids=[],
    3207 -                track_indices=[],
    3208 -                seed_positions=[],
    3209 -                segment_diagnostics=[],
    3210 -                stats={},
    3211 -                success=False,
    3212 -                failure_reason=failure,
    3213 -            )
    3214 -
    3215 -        soft_genre_penalty_hits_total += int(soft_genre_penalty_hits_segment)
    3216 -        soft_genre_penalty_edges_scored_total += int(soft_genre_penalty_edges_scored_segment)
    3217 -        if cfg.genre_penalty_strength > 0 and logger.isEnabledFor(logging.DEBUG):
    3218 -            logger.debug(
    3219 -                "Segment %d: soft_genre_penalty_hits=%d edges_scored=%d threshold=%.2f strength=%.2f",
    3220 -                seg_idx,
    3221 -                int(soft_genre_penalty_hits_segment),
    3222 -                int(soft_genre_penalty_edges_scored_segment),
    3223 -                float(cfg.genre_penalty_threshold),
    3224 -                float(cfg.genre_penalty_strength),
    3225 -            )
    3226 -
    3227 -        # Compute edge scores for diagnostics
    3228 -        full_segment = [pier_a] + segment_path + [pier_b]
    3229 -        worst_edge, mean_edge = _compute_edge_scores(
    3230 -            full_segment, X_full_tr_norm, X_start_tr_norm, X_mid_tr_norm, X_end_tr_norm, cfg
    3231 -        )
    3232 -
    3233 -        # Record diagnostics
    3234 -        diagnostics.append(SegmentDiagnostics(
    3235 -            pier_a_id=pier_a_id,
    3236 -            pier_b_id=pier_b_id,
    3237 -            target_length=interior_len,
    3238 -            actual_length=len(segment_path),
    3239 -            pool_size_initial=pool_size_initial,
    3240 -            pool_size_final=pool_size_final,
    3241 -            expansions=expansions,
    3242 -            beam_width_used=beam_width_used,
    3243 -            worst_edge_score=worst_edge,
    3244 -            mean_edge_score=mean_edge,
    3245 -            success=segment_path is not None and len(segment_path) == interior_len,
    3246 -            bridge_floor_used=float(chosen_bridge_floor),
    3247 -            backoff_attempts_used=int(backoff_used_count),
    3248 -            widened_search=bool(widened_search_used),
    3249 -        ))
    3250 -        segment_bridge_floors_used.append(float(chosen_bridge_floor))
    3251 -        segment_backoff_attempts_used.append(int(backoff_used_count))
    3252 -        logger.info(
    3253 -            "Segment %d: %s -> %s bridge_floor=%.2f pool_before=%d pool_after=%d",
    3254 -            seg_idx, pier_a_id, pier_b_id, float(chosen_bridge_floor), pool_size_initial, pool_size_final,
    3255 -        )
    3256 -        # DEBUG top candidates for this segment
    3257 -        if logger.isEnabledFor(logging.DEBUG):
    3258 -            scores_dbg = []
    3259 -            sim_to_a = np.dot(X_full_norm, X_full_norm[pier_a])
    3260 -            sim_to_b = np.dot(X_full_norm, X_full_norm[pier_b])
    3261 -            for cand in segment_candidates[: min(200, len(segment_candidates))]:
    3262 -                sim_a = float(sim_to_a[cand])
    3263 -                sim_b = float(sim_to_b[cand])
    3264 -                denom = sim_a + sim_b
    3265 -                hmean = 0.0 if denom <= 1e-9 else (2 * sim_a * sim_b) / denom
    3266 -                trans = _compute_transition_score(
    3267 -                    cand,
    3268 -                    pier_b,
    3269 -                    X_full_tr_norm,
    3270 -                    X_start_tr_norm,
    3271 -                    X_mid_tr_norm,
    3272 -                    X_end_tr_norm,
    3273 -                    cfg,
    3274 -                )
    3275 -                final_score = cfg.weight_bridge * hmean + cfg.weight_transition * trans
    3276 -                scores_dbg.append((final_score, sim_a, sim_b, hmean, trans, cand))
    3277 -            scores_dbg = sorted(scores_dbg, key=lambda t: t[0], reverse=True)[:10]
    3278 -            dbg_rows = []
    3279 -            for final_score, sim_a, sim_b, hmean, trans, cand in scores_dbg:
    3280 -                keys = identity_keys_for_index(bundle, int(cand))
    3281 -                artist = (
    3282 -                    str(bundle.track_artists[cand])
    3283 -                    if bundle.track_artists is not None
    3284 -                    else (str(bundle.artist_keys[cand]) if bundle.artist_keys is not None else "")
    3285 -                )
    3286 -                title = str(bundle.track_titles[cand]) if bundle.track_titles is not None else ""
    3287 -                dbg_rows.append({
    3288 -                    "track_id": str(bundle.track_ids[cand]),
    3289 -                    "artist": sanitize_for_logging(artist),
    3290 -                    "title": sanitize_for_logging(title),
    3291 -                    "artist_key": keys.artist_key,
    3292 -                    "title_key": keys.title_key,
    3293 -                    "simA": round(sim_a, 3),
    3294 -                    "simB": round(sim_b, 3),
    3295 -                    "hmean": round(hmean, 3),
    3296 -                    "transition": round(trans, 3),
    3297 -                    "final": round(final_score, 3),
    3298 -                    "internal": bool(internal_connector_indices and cand in internal_connector_indices),
    3299 -                })
    3300 -            logger.debug("Segment %d top candidates: %s", seg_idx, dbg_rows)
    3301 -
    3302 -        # Commit segment path to used set
    3303 -        for idx in segment_path:
    3304 -            global_used.add(idx)
    3305 -            try:
    3306 -                used_track_keys.add(identity_keys_for_index(bundle, int(idx)).track_key)
    3307 -            except Exception:
    3308 -                continue
    3309 -
    3310 -        all_segments.append(full_segment)
    3311 -
    3312 -        # Update boundary context for next segment (cross-segment min_gap enforcement)
    3313 -        # Build the concatenated result so far to extract recent artists
    3314 -        current_concat: List[int] = []
    3315 -        for concat_seg_idx, concat_seg in enumerate(all_segments):
    3316 -            if concat_seg_idx == 0:
    3317 -                current_concat.extend(concat_seg)
    3318 -            else:
    3319 -                current_concat.extend(concat_seg[1:])  # Drop duplicate pier
    3320 -
    3321 -        # Extract artist keys from the last MIN_GAP_GLOBAL positions
    3322 -        # If artist_identity_cfg is enabled, resolve to identity keys (collapsing ensemble variants)
    3323 -        recent_boundary_artists = []
    3324 -        start_pos = max(0, len(current_concat) - MIN_GAP_GLOBAL)
    3325 -        use_identity = artist_identity_cfg is not None and artist_identity_cfg.enabled
    3326 -
    3327 -        for pos in range(start_pos, len(current_concat)):
    3328 -            try:
    3329 -                if use_identity:
    3330 -                    # Identity mode: resolve artist string to identity keys
    3331 -                    artist_str = identity_keys_for_index(bundle, int(current_concat[pos])).artist
    3332 -                    if artist_str:
    3333 -                        identity_keys_set = resolve_artist_identity_keys(artist_str, artist_identity_cfg)
    3334 -                        # Add ALL identity keys to boundary tracking
    3335 -                        for identity_key in identity_keys_set:
    3336 -                            recent_boundary_artists.append(identity_key)
    3337 -                else:
    3338 -                    # Legacy mode: single artist_key
    3339 -                    artist_key = identity_keys_for_index(bundle, int(current_concat[pos])).artist_key
    3340 -                    if artist_key:
    3341 -                        recent_boundary_artists.append(str(artist_key))
    3342 -            except Exception:
    3343 -                continue
    3344 -
    3345 -    # Concatenate segments
    3346 -    # First segment: keep full [A, ..., B]
    3347 -    # Subsequent segments: drop first element (the pier) to avoid duplication
    3348 -    # Single-seed arc: drop last element (the duplicated seed) to avoid repetition
    3349 -    final_indices: List[int] = []
    3350 -    seed_positions: List[int] = []
    3351 -
    3352 -    if is_single_seed_arc:
    3353 -        # Single-seed arc: segment is [seed, interior..., seed]
    3354 -        # Output only [seed, interior...] to avoid duplicate seed at end
    3355 -        segment = all_segments[0] if all_segments else [ordered_seeds[0]]
    3356 -        final_indices = segment[:-1]  # Drop the trailing duplicate seed
    3357 -        seed_positions = [0]  # Seed is at position 0
    3358 -        logger.info("Pier+Bridge: single-seed arc output: %d tracks (seed at start, arc returns to seed-similar)", len(final_indices))
    3359 -    else:
    3360 -        for seg_idx, segment in enumerate(all_segments):
    3361 -            if seg_idx == 0:
    3362 -                final_indices.extend(segment)
    3363 -                seed_positions.append(0)  # First pier
    3364 -                seed_positions.append(len(final_indices) - 1)  # Second pier
    3365 -            else:
    3366 -                # Drop first element (the pier, already included)
    3367 -                final_indices.extend(segment[1:])
    3368 -                seed_positions.append(len(final_indices) - 1)  # New pier
    3369 -
    3370 -    # Convert to track IDs
    3371 -    # Cross-segment min_gap is enforced DURING generation (boundary-aware beam search),
    3372 -    # not as a post-order filter. This ensures exact length guarantees.
    3373 -    final_track_ids = [str(bundle.track_ids[i]) for i in final_indices]
    3374 -
    3375 -    # Strict length validation: pier-bridge must return EXACTLY the requested number of tracks
    3376 -    if len(final_track_ids) != total_tracks:
    3377 -        failure_msg = (
    3378 -            f"Pier-bridge length mismatch: generated {len(final_track_ids)} tracks "
    3379 -            f"but expected exactly {total_tracks}. This indicates a bug in segment generation."
    3380 -        )
    3381 -        logger.error(failure_msg)
    3382 -        return PierBridgeResult(
    3383 -            track_ids=[],
    3384 -            track_indices=[],
    3385 -            seed_positions=[],
    3386 -            segment_diagnostics=diagnostics,
    3387 -            stats={"error": "length_mismatch", "expected": total_tracks, "actual": len(final_track_ids)},
    3388 -            success=False,
    3389 -            failure_reason=failure_msg,
    3390 -        )
    3391 -
    3392 -    # Compute per-edge transition scores for reporting (matches builder scoring)
    3393 -    edge_scores: list[dict[str, Any]] = []
    3394 -    transition_vals: list[float] = []
    3395 -    for i in range(1, len(final_indices)):
    3396 -        prev_idx = final_indices[i - 1]
    3397 -        cur_idx = final_indices[i]
    3398 -        t_val = _compute_transition_score(
    3399 -            prev_idx,
    3400 -            cur_idx,
    3401 -            X_full_tr_norm,
    3402 -            X_start_tr_norm,
    3403 -            X_mid_tr_norm,
    3404 -            X_end_tr_norm,
    3405 -            cfg,
    3406 -        )
    3407 -        s_val = float(np.dot(X_full_norm[prev_idx], X_full_norm[cur_idx]))
    3408 -        g_val = None
    3409 -        if X_genre_norm is not None:
    3410 -            g_val = float(np.dot(X_genre_norm[prev_idx], X_genre_norm[cur_idx]))
    3411 -        transition_vals.append(float(t_val))
    3412 -        edge_scores.append(
    3413 -            {
    3414 -                "prev_id": str(bundle.track_ids[prev_idx]),
    3415 -                "cur_id": str(bundle.track_ids[cur_idx]),
    3416 -                "prev_idx": int(prev_idx),
    3417 -                "cur_idx": int(cur_idx),
    3418 -                "T": float(t_val),
    3419 -                "S": float(s_val),
    3420 -                "G": (float(g_val) if g_val is not None else None),
    3421 -            }
    3422 -        )
    3423 -
    3424 -    # Recompute seed positions from final track IDs for diagnostic accuracy
    3425 -    seed_positions = [idx for idx, tid in enumerate(final_track_ids) if tid in seed_id_set]
    3426 -    if len(seed_positions) != (1 if is_single_seed_arc else len(seed_id_set)):
    3427 -        logger.warning(
    3428 -            "Pier+Bridge: seed count mismatch in final result (expected %d, found %d)",
    3429 -            (1 if is_single_seed_arc else len(seed_id_set)),
    3430 -            len(seed_positions),
    3431 -        )
    3432 -
    3433 -    # Compute overall stats
    3434 -    actual_num_seeds = 1 if is_single_seed_arc else len(seed_indices)
    3435 -    stats = {
    3436 -        "num_seeds": actual_num_seeds,
    3437 -        "single_seed_arc": is_single_seed_arc,
    3438 -        "target_tracks": total_tracks,
    3439 -        "actual_tracks": len(final_indices),
    3440 -        "universe_size": len(universe),
    3441 -        "segments_built": len(all_segments),
    3442 -        "segments_successful": sum(1 for d in diagnostics if d.success),
    3443 -        "total_expansions": sum(d.expansions for d in diagnostics),
    3444 -        "edge_scores": edge_scores,
    3445 -        "min_transition": float(np.min(transition_vals)) if transition_vals else None,
    3446 -        "mean_transition": float(np.mean(transition_vals)) if transition_vals else None,
    3447 -        "transition_centered": bool(cfg.center_transitions),
    3448 -        "soft_genre_penalty_hits": int(soft_genre_penalty_hits_total),
    3449 -        "soft_genre_penalty_edges_scored": int(soft_genre_penalty_edges_scored_total),
    3450 -        "segment_bridge_floors_used": [float(x) for x in segment_bridge_floors_used],
    3451 -        "segment_backoff_attempts_used": [int(x) for x in segment_backoff_attempts_used],
    3452 -        "warnings": warnings,
    3453 -        "config": {
    3454 -            "transition_floor": cfg.transition_floor,
    3455 -            "transition_weights": cfg.transition_weights,
    3456 -            "initial_neighbors_m": cfg.initial_neighbors_m,
    3457 -            "initial_beam_width": cfg.initial_beam_width,
    3458 -            "eta_destination_pull": cfg.eta_destination_pull,
    3459 -            "genre_tiebreak_weight": float(cfg.genre_tiebreak_weight),
    3460 -            "genre_penalty_threshold": float(cfg.genre_penalty_threshold),
    3461 -            "genre_penalty_strength": float(cfg.genre_penalty_strength),
    3462 -            "genre_tie_break_band": (
    3463 -                float(cfg.genre_tie_break_band) if cfg.genre_tie_break_band is not None else None
    3464 -            ),
    3465 -            "bridge_floor": float(cfg.bridge_floor),
    3466 -            "infeasible_handling_enabled": bool(infeasible_handling and infeasible_handling.enabled),
    3467 -            "experiment_bridge_scoring": {
    3468 -                "enabled": bool(cfg.experiment_bridge_scoring_enabled),
    3469 -                "min_weight": float(cfg.experiment_bridge_min_weight),
    3470 -                "balance_weight": float(cfg.experiment_bridge_balance_weight),
    3471 -            },
    3472 -            "dj_bridging": {
    3473 -                "enabled": bool(cfg.dj_bridging_enabled),
    3474 -                "seed_ordering": str(cfg.dj_seed_ordering),
    3475 -                "anchors_must_include_all": bool(cfg.dj_anchors_must_include_all),
    3476 -                "route_shape": str(cfg.dj_route_shape),
    3477 -                "waypoint_weight": float(cfg.dj_waypoint_weight),
    3478 -                "waypoint_floor": float(cfg.dj_waypoint_floor),
    3479 -                "waypoint_penalty": float(cfg.dj_waypoint_penalty),
    3480 -                "waypoint_tie_break_band": (
    3481 -                    float(cfg.dj_waypoint_tie_break_band) if cfg.dj_waypoint_tie_break_band is not None else None
    3482 -                ),
    3483 -                "waypoint_cap": float(cfg.dj_waypoint_cap),
    3484 -                "seed_ordering_weights": {
    3485 -                    "sonic": float(cfg.dj_seed_ordering_weight_sonic),
    3486 -                    "genre": float(cfg.dj_seed_ordering_weight_genre),
    3487 -                    "bridge": float(cfg.dj_seed_ordering_weight_bridge),
    3488 -                },
    3489 -                "pool_strategy": str(cfg.dj_pool_strategy),
    3490 -                "pool_union_max": int(cfg.dj_pool_union_max),
    3491 -                "pool_topk_bridge": int(cfg.dj_pool_topk_bridge),
    3492 -                "pool_topk_toward_b_per_step": int(cfg.dj_pool_topk_toward_b_per_step),
    3493 -                "pool_topk_genre_per_step": int(cfg.dj_pool_topk_genre_per_step),
    3494 -                "pool_step_stride": int(cfg.dj_pool_step_stride),
    3495 -                "allow_detours_when_far": bool(cfg.dj_allow_detours_when_far),
    3496 -                "far_thresholds": {
    3497 -                    "sonic": float(cfg.dj_far_threshold_sonic),
    3498 -                    "genre": float(cfg.dj_far_threshold_genre),
    3499 -                    "connector_scarcity": float(cfg.dj_far_threshold_connector_scarcity),
    3500 -                },
    3501 -                "connector_bias": {
    3502 -                    "enabled": bool(cfg.dj_connector_bias_enabled),
    3503 -                    "max_per_segment_linear": int(cfg.dj_connector_max_per_segment_linear),
    3504 -                    "max_per_segment_adventurous": int(cfg.dj_connector_max_per_segment_adventurous),
    3505 -                },
    3506 -                "ladder": {
    3507 -                    "top_labels": int(cfg.dj_ladder_top_labels),
    3508 -                    "min_label_weight": float(cfg.dj_ladder_min_label_weight),
    3509 -                    "min_similarity": float(cfg.dj_ladder_min_similarity),
    3510 -                    "max_steps": int(cfg.dj_ladder_max_steps),
    3511 -                },
    3512 -                "waypoint_fallback_k": int(cfg.dj_waypoint_fallback_k),
    3513 -                "micro_piers": {
    3514 -                    "enabled": bool(cfg.dj_micro_piers_enabled),
    3515 -                    "max": int(cfg.dj_micro_piers_max),
    3516 -                    "topk": int(cfg.dj_micro_piers_topk),
    3517 -                },
    3518 -            },
    3519 -            "progress_arc": {
    3520 -                "enabled": bool(cfg.progress_arc_enabled),
    3521 -                "weight": float(cfg.progress_arc_weight),
    3522 -                "shape": str(cfg.progress_arc_shape),
    3523 -                "tolerance": float(cfg.progress_arc_tolerance),
    3524 -                "loss": str(cfg.progress_arc_loss),
    3525 -                "huber_delta": float(cfg.progress_arc_huber_delta),
    3526 -                "max_step": (float(cfg.progress_arc_max_step) if cfg.progress_arc_max_step is not None else None),
    3527 -                "max_step_mode": str(cfg.progress_arc_max_step_mode),
    3528 -                "max_step_penalty": float(cfg.progress_arc_max_step_penalty),
    3529 -                "autoscale": {
    3530 -                    "enabled": bool(cfg.progress_arc_autoscale_enabled),
    3531 -                    "min_distance": float(cfg.progress_arc_autoscale_min_distance),
    3532 -                    "distance_scale": float(cfg.progress_arc_autoscale_distance_scale),
    3533 -                    "per_step_scale": bool(cfg.progress_arc_autoscale_per_step_scale),
    3534 -                },
    3535 -            },
    3536 -        },
    3537 -    }
    3538 -
    3539 -    logger.info("Pier+Bridge complete: %d tracks, %d segments, %d successful",
    3540 -               len(final_indices), len(all_segments),
    3541 -               sum(1 for d in diagnostics if d.success))
    3542 -
    3543 -    return PierBridgeResult(
    3544 -        track_ids=final_track_ids,
    3545 -        track_indices=final_indices,
    3546 -        seed_positions=seed_positions,
    3547 -        segment_diagnostics=diagnostics,
    3548 -        stats=stats,
    3549 -    )
    3550 -
    3551 -
    3552 -def generate_pier_bridge_playlist(
    3553 -    *,
    3554 -    artifact_path: str,
    3555 -    seed_track_ids: List[str],
    3556 -    total_tracks: int,
    3557 -    mode: str = "dynamic",
    3558 -    random_seed: int = 0,
    3559 -    min_genre_similarity: Optional[float] = None,
    3560 -    genre_method: str = "ensemble",
    3561 -    transition_floor: Optional[float] = None,
    3562 -) -> PierBridgeResult:
    3563 -    """
    3564 -    High-level entry point for pier+bridge playlist generation.
    3565 -
    3566 -    Loads artifacts, builds candidate pool, and runs pier+bridge construction.
    3567 -    """
    3568 -    from src.features.artifacts import load_artifact_bundle
    3569 -    from src.playlist.config import default_ds_config
    3570 -    from src.playlist.candidate_pool import build_candidate_pool
    3571 -    from src.similarity.hybrid import build_hybrid_embedding
    3572 -    from src.similarity.sonic_variant import compute_sonic_variant_matrix, resolve_sonic_variant
    3573 -
    3574 -    bundle = load_artifact_bundle(artifact_path)
    3575 -
    3576 -    # Validate seeds
    3577 -    valid_seed_ids = []
    3578 -    for tid in seed_track_ids:
    3579 -        if str(tid) in bundle.track_id_to_index:
    3580 -            valid_seed_ids.append(str(tid))
    3581 -        else:
    3582 -            logger.warning("Seed track not found, skipping: %s", tid)
    3583 -
    3584 -    if not valid_seed_ids:
    3585 -        raise ValueError("No valid seed tracks found in artifact bundle")
    3586 -
    3587 -    seed_idx = bundle.track_id_to_index[valid_seed_ids[0]]
    3588 -
    3589 -    # Build config
    3590 -    cfg = default_ds_config(mode, playlist_len=total_tracks)
    3591 -
    3592 -    # Build embedding
    3593 -    resolved_variant = resolve_sonic_variant()
    3594 -    X_sonic_for_embed, _ = compute_sonic_variant_matrix(bundle.X_sonic, resolved_variant, l2=False)
    3595 -
    3596 -    embedding_model = build_hybrid_embedding(
    3597 -        X_sonic_for_embed,
    3598 -        bundle.X_genre_smoothed,
    3599 -        n_components_sonic=32,
    3600 -        n_components_genre=32,
    3601 -        w_sonic=0.6,
    3602 -        w_genre=0.4,
    3603 -        random_seed=random_seed,
    3604 -    )
    3605 -
    3606 -    # Build candidate pool (for genre gating)
    3607 -    pool = build_candidate_pool(
    3608 -        seed_idx=seed_idx,
    3609 -        seed_indices=[seed_idx],
    3610 -        embedding=embedding_model.embedding,
    3611 -        artist_keys=bundle.artist_keys,
    3612 -        track_ids=bundle.track_ids,
    3613 -        track_titles=bundle.track_titles,
    3614 -        track_artists=bundle.track_artists,
    3615 -        durations_ms=bundle.durations_ms,
    3616 -        cfg=cfg.candidate,
    3617 -        random_seed=random_seed,
    3618 -        X_sonic=X_sonic_for_embed,
    3619 -        X_genre_raw=bundle.X_genre_raw if min_genre_similarity else None,
    3620 -        X_genre_smoothed=bundle.X_genre_smoothed if min_genre_similarity else None,
    3621 -        min_genre_similarity=min_genre_similarity,
    3622 -        genre_method=genre_method,
    3623 -        mode=mode,
    3624 -    )
    3625 -
    3626 -    # Build pier config
    3627 -    pier_cfg = PierBridgeConfig()
    3628 -    if transition_floor is not None:
    3629 -        pier_cfg = PierBridgeConfig(transition_floor=transition_floor)
    3630 -    else:
    3631 -        pier_cfg = PierBridgeConfig(transition_floor=cfg.construct.transition_floor)
    3632 -
    3633 -    return build_pier_bridge_playlist(
    3634 -        seed_track_ids=valid_seed_ids,
    3635 -        total_tracks=total_tracks,
    3636 -        bundle=bundle,
    3637 -        candidate_pool_indices=list(pool.pool_indices),
    3638 -        cfg=pier_cfg,
    3639 -        min_genre_similarity=min_genre_similarity,
    3640 -        X_genre_smoothed=bundle.X_genre_smoothed,
    3641 -        genre_method=genre_method,
    3642 -    )